{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26181c15",
   "metadata": {},
   "source": [
    "<h1>Problem Set - 3</h1>\n",
    "<h4> Data Programming </h4>\n",
    "<br>\n",
    "<b>Performed by: </b> Bikram Lamsal<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6b95e",
   "metadata": {},
   "source": [
    "<h2>Question - 1</h2>\n",
    "Introduction:<br>\n",
    "Special thanks to: https://github.com/justmarkham for sharing the dataset and \n",
    "materials.<br><br>\n",
    "Occupations<br>\n",
    "Step 1. Import the necessary libraries<br>\n",
    "Step 2. Import the dataset from this address<br>\n",
    "Step 3. Assign it to a variable called users<br>\n",
    "Step 4. Discover what is the mean age per occupation<br>\n",
    "Step 5. Discover the Male ratio per occupation and sort it from the most to the least <br>\n",
    "Step 6. For each occupation, calculate the minimum and maximum ages <br>\n",
    "Step 7. For each combination of occupation and sex, calculate the mean age <br>\n",
    "Step 8. For each occupation present the percentage of women and men <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3fedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "#  Import the dataset\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user\"\n",
    "\n",
    "#  Assign the dataset to a variable called 'users'\n",
    "users = pd.read_csv(url, sep='|', index_col='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fd4891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Age per Occupation:\n",
      "| occupation    |     age |\n",
      "|:--------------|--------:|\n",
      "| administrator | 38.7468 |\n",
      "| artist        | 31.3929 |\n",
      "| doctor        | 43.5714 |\n",
      "| educator      | 42.0105 |\n",
      "| engineer      | 36.3881 |\n",
      "| entertainment | 29.2222 |\n",
      "| executive     | 38.7188 |\n",
      "| healthcare    | 41.5625 |\n",
      "| homemaker     | 32.5714 |\n",
      "| lawyer        | 36.75   |\n",
      "| librarian     | 40      |\n",
      "| marketing     | 37.6154 |\n",
      "| none          | 26.5556 |\n",
      "| other         | 34.5238 |\n",
      "| programmer    | 33.1212 |\n",
      "| retired       | 63.0714 |\n",
      "| salesman      | 35.6667 |\n",
      "| scientist     | 35.5484 |\n",
      "| student       | 22.0816 |\n",
      "| technician    | 33.1481 |\n",
      "| writer        | 36.3111 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Discover the mean age per occupation\n",
    "mean_age_per_occupation = users.groupby('occupation')['age'].mean()\n",
    "\n",
    "# Displays the mean age per Occupation in a tabular format\n",
    "print(\"Mean Age per Occupation:\")\n",
    "print(mean_age_per_occupation.to_markdown())  \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cde7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Ratio per Occupation:\n",
      "| occupation    |   gender |\n",
      "|:--------------|---------:|\n",
      "| doctor        | 1        |\n",
      "| engineer      | 0.970149 |\n",
      "| technician    | 0.962963 |\n",
      "| retired       | 0.928571 |\n",
      "| programmer    | 0.909091 |\n",
      "| executive     | 0.90625  |\n",
      "| scientist     | 0.903226 |\n",
      "| entertainment | 0.888889 |\n",
      "| lawyer        | 0.833333 |\n",
      "| salesman      | 0.75     |\n",
      "| educator      | 0.726316 |\n",
      "| student       | 0.693878 |\n",
      "| other         | 0.657143 |\n",
      "| marketing     | 0.615385 |\n",
      "| writer        | 0.577778 |\n",
      "| none          | 0.555556 |\n",
      "| administrator | 0.544304 |\n",
      "| artist        | 0.535714 |\n",
      "| librarian     | 0.431373 |\n",
      "| healthcare    | 0.3125   |\n",
      "| homemaker     | 0.142857 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Discover the Male ratio per occupation\n",
    "def male_ratio(group):\n",
    "    return (group == 'M').sum() / group.count()\n",
    "\n",
    "male_ratio_per_occupation = users.groupby('occupation')['gender'].apply(male_ratio)\n",
    "male_ratio_in_order = male_ratio_per_occupation.sort_values(ascending=False)\n",
    "\n",
    "# Displays the male ratio per occupation in tabular format\n",
    "print(\"Male Ratio per Occupation:\")\n",
    "print(male_ratio_in_order.to_markdown())  \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ad0193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Range per Occupation:\n",
      "| occupation    |   min |   max |\n",
      "|:--------------|------:|------:|\n",
      "| administrator |    21 |    70 |\n",
      "| artist        |    19 |    48 |\n",
      "| doctor        |    28 |    64 |\n",
      "| educator      |    23 |    63 |\n",
      "| engineer      |    22 |    70 |\n",
      "| entertainment |    15 |    50 |\n",
      "| executive     |    22 |    69 |\n",
      "| healthcare    |    22 |    62 |\n",
      "| homemaker     |    20 |    50 |\n",
      "| lawyer        |    21 |    53 |\n",
      "| librarian     |    23 |    69 |\n",
      "| marketing     |    24 |    55 |\n",
      "| none          |    11 |    55 |\n",
      "| other         |    13 |    64 |\n",
      "| programmer    |    20 |    63 |\n",
      "| retired       |    51 |    73 |\n",
      "| salesman      |    18 |    66 |\n",
      "| scientist     |    23 |    55 |\n",
      "| student       |     7 |    42 |\n",
      "| technician    |    21 |    55 |\n",
      "| writer        |    18 |    60 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the minimum and maximum ages per occupation\n",
    "age_range_per_occupation = users.groupby('occupation')['age'].agg(['min', 'max'])\n",
    "\n",
    "# Displays the age range per occupation data in tabular format\n",
    "print(\"Age Range per Occupation:\")\n",
    "print(age_range_per_occupation.to_markdown())  \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c3e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Age per Occupation and Gender:\n",
      "|                        |     age |\n",
      "|:-----------------------|--------:|\n",
      "| ('administrator', 'F') | 40.6389 |\n",
      "| ('administrator', 'M') | 37.1628 |\n",
      "| ('artist', 'F')        | 30.3077 |\n",
      "| ('artist', 'M')        | 32.3333 |\n",
      "| ('doctor', 'M')        | 43.5714 |\n",
      "| ('educator', 'F')      | 39.1154 |\n",
      "| ('educator', 'M')      | 43.1014 |\n",
      "| ('engineer', 'F')      | 29.5    |\n",
      "| ('engineer', 'M')      | 36.6    |\n",
      "| ('entertainment', 'F') | 31      |\n",
      "| ('entertainment', 'M') | 29      |\n",
      "| ('executive', 'F')     | 44      |\n",
      "| ('executive', 'M')     | 38.1724 |\n",
      "| ('healthcare', 'F')    | 39.8182 |\n",
      "| ('healthcare', 'M')    | 45.4    |\n",
      "| ('homemaker', 'F')     | 34.1667 |\n",
      "| ('homemaker', 'M')     | 23      |\n",
      "| ('lawyer', 'F')        | 39.5    |\n",
      "| ('lawyer', 'M')        | 36.2    |\n",
      "| ('librarian', 'F')     | 40      |\n",
      "| ('librarian', 'M')     | 40      |\n",
      "| ('marketing', 'F')     | 37.2    |\n",
      "| ('marketing', 'M')     | 37.875  |\n",
      "| ('none', 'F')          | 36.5    |\n",
      "| ('none', 'M')          | 18.6    |\n",
      "| ('other', 'F')         | 35.4722 |\n",
      "| ('other', 'M')         | 34.029  |\n",
      "| ('programmer', 'F')    | 32.1667 |\n",
      "| ('programmer', 'M')    | 33.2167 |\n",
      "| ('retired', 'F')       | 70      |\n",
      "| ('retired', 'M')       | 62.5385 |\n",
      "| ('salesman', 'F')      | 27      |\n",
      "| ('salesman', 'M')      | 38.5556 |\n",
      "| ('scientist', 'F')     | 28.3333 |\n",
      "| ('scientist', 'M')     | 36.3214 |\n",
      "| ('student', 'F')       | 20.75   |\n",
      "| ('student', 'M')       | 22.6691 |\n",
      "| ('technician', 'F')    | 38      |\n",
      "| ('technician', 'M')    | 32.9615 |\n",
      "| ('writer', 'F')        | 37.6316 |\n",
      "| ('writer', 'M')        | 35.3462 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean age per combination of occupation and sex\n",
    "mean_age_per_combination = users.groupby(['occupation', 'gender'])['age'].mean()\n",
    "\n",
    "# Displays the mean age per occupation and gender in tabular format\n",
    "print(\"Mean Age per Occupation and Gender:\")\n",
    "print(mean_age_per_combination.to_markdown())  \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28a7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Percentage per Occupation:\n",
      "| occupation    | level_1   |    gender |\n",
      "|:--------------|:----------|----------:|\n",
      "| administrator | Female %  |  45.5696  |\n",
      "| administrator | Male %    |  54.4304  |\n",
      "| artist        | Female %  |  46.4286  |\n",
      "| artist        | Male %    |  53.5714  |\n",
      "| doctor        | Female %  |   0       |\n",
      "| doctor        | Male %    | 100       |\n",
      "| educator      | Female %  |  27.3684  |\n",
      "| educator      | Male %    |  72.6316  |\n",
      "| engineer      | Female %  |   2.98507 |\n",
      "| engineer      | Male %    |  97.0149  |\n",
      "| entertainment | Female %  |  11.1111  |\n",
      "| entertainment | Male %    |  88.8889  |\n",
      "| executive     | Female %  |   9.375   |\n",
      "| executive     | Male %    |  90.625   |\n",
      "| healthcare    | Female %  |  68.75    |\n",
      "| healthcare    | Male %    |  31.25    |\n",
      "| homemaker     | Female %  |  85.7143  |\n",
      "| homemaker     | Male %    |  14.2857  |\n",
      "| lawyer        | Female %  |  16.6667  |\n",
      "| lawyer        | Male %    |  83.3333  |\n",
      "| librarian     | Female %  |  56.8627  |\n",
      "| librarian     | Male %    |  43.1373  |\n",
      "| marketing     | Female %  |  38.4615  |\n",
      "| marketing     | Male %    |  61.5385  |\n",
      "| none          | Female %  |  44.4444  |\n",
      "| none          | Male %    |  55.5556  |\n",
      "| other         | Female %  |  34.2857  |\n",
      "| other         | Male %    |  65.7143  |\n",
      "| programmer    | Female %  |   9.09091 |\n",
      "| programmer    | Male %    |  90.9091  |\n",
      "| retired       | Female %  |   7.14286 |\n",
      "| retired       | Male %    |  92.8571  |\n",
      "| salesman      | Female %  |  25       |\n",
      "| salesman      | Male %    |  75       |\n",
      "| scientist     | Female %  |   9.67742 |\n",
      "| scientist     | Male %    |  90.3226  |\n",
      "| student       | Female %  |  30.6122  |\n",
      "| student       | Male %    |  69.3878  |\n",
      "| technician    | Female %  |   3.7037  |\n",
      "| technician    | Male %    |  96.2963  |\n",
      "| writer        | Female %  |  42.2222  |\n",
      "| writer        | Male %    |  57.7778  |\n"
     ]
    }
   ],
   "source": [
    "#  Calculate the percentage of women and men per occupation\n",
    "def gender_percentage(group):\n",
    "    total_count = group.count()\n",
    "    \n",
    "    female_count = (group == 'F').sum()\n",
    "    female_percentage = (female_count / total_count) * 100\n",
    "    \n",
    "    male_count = total_count - female_count\n",
    "    male_percentage = (male_count / total_count) * 100\n",
    "    \n",
    "    return pd.Series({'Female %': female_percentage, 'Male %': male_percentage})\n",
    "\n",
    "gender_percentage_per_occupation = users.groupby('occupation')['gender'].apply(gender_percentage)\n",
    "gender_percentage_per_occupation = gender_percentage_per_occupation.reset_index()\n",
    "\n",
    "# Displays the gender percentage per occupation in tabular format\n",
    "print(\"Gender Percentage per Occupation:\")\n",
    "print(gender_percentage_per_occupation.to_markdown(index=False))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7c90e",
   "metadata": {},
   "source": [
    "<h2>Question 2</h2>\n",
    "Euro Teams<br>\n",
    "Step 1. Import the necessary libraries<br>\n",
    "Step 2. Import the dataset from this address<br>\n",
    "Step 3. Assign it to a variable called euro12 <br>\n",
    "Step 4. Select only the Goal column<br>\n",
    "Step 5. How many team participated in the Euro2012? <br>\n",
    "Step 6. What is the number of columns in the dataset?<br>\n",
    "Step 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline<br>\n",
    "Step 8. Sort the teams by Red Cards, then to Yellow Cards <br>\n",
    "Step 9. Calculate the mean Yellow Cards given per Team<br>\n",
    "Step 10. Filter teams that scored more than 6 goalsStep 11. Select the teams that start with G<br>\n",
    "Step 12. Select the first 7 columns<br>\n",
    "Step 13. Select all columns except the last 3<br>\n",
    "Step 14. Present only the Shooting Accuracy from England, Italy and Russia<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131ebf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "#  Impotr the dataset\n",
    "url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv\"\n",
    "\n",
    "#Assign the dataset to a variable named 'euro12'\n",
    "euro12 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ce5d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Goals \n",
      "|    |   Goals |\n",
      "|---:|--------:|\n",
      "|  0 |       4 |\n",
      "|  1 |       4 |\n",
      "|  2 |       4 |\n",
      "|  3 |       5 |\n",
      "|  4 |       3 |\n",
      "|  5 |      10 |\n",
      "|  6 |       5 |\n",
      "|  7 |       6 |\n",
      "|  8 |       2 |\n",
      "|  9 |       2 |\n",
      "| 10 |       6 |\n",
      "| 11 |       1 |\n",
      "| 12 |       5 |\n",
      "| 13 |      12 |\n",
      "| 14 |       5 |\n",
      "| 15 |       2 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the 'Goals' column\n",
    "goals = euro12['Goals']\n",
    "\n",
    "# Displays the 'Goals' column in tabular format\n",
    "print(\" Goals \")\n",
    "print(goals.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53d9719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of participating teams in Euro 2012:  16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  How many teams participated in Euro2012?\n",
    "participating_teams = euro12['Team'].nunique()\n",
    "\n",
    "# Displays the total number of participating teams\n",
    "print(\"Total number of participating teams in Euro 2012: \", participating_teams)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bdd18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns in the dataset:  35\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Number of columns in the dataset\n",
    "num_columns = euro12.shape[1]\n",
    "\n",
    "# Displays the total number of columns\n",
    "print(\"Total number of columns in the dataset: \", num_columns)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fccb936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Discipline Performance:\n",
      "|    | Team                |   Yellow Cards |   Red Cards |\n",
      "|---:|:--------------------|---------------:|------------:|\n",
      "|  0 | Croatia             |              9 |           0 |\n",
      "|  1 | Czech Republic      |              7 |           0 |\n",
      "|  2 | Denmark             |              4 |           0 |\n",
      "|  3 | England             |              5 |           0 |\n",
      "|  4 | France              |              6 |           0 |\n",
      "|  5 | Germany             |              4 |           0 |\n",
      "|  6 | Greece              |              9 |           1 |\n",
      "|  7 | Italy               |             16 |           0 |\n",
      "|  8 | Netherlands         |              5 |           0 |\n",
      "|  9 | Poland              |              7 |           1 |\n",
      "| 10 | Portugal            |             12 |           0 |\n",
      "| 11 | Republic of Ireland |              6 |           1 |\n",
      "| 12 | Russia              |              6 |           0 |\n",
      "| 13 | Spain               |             11 |           0 |\n",
      "| 14 | Sweden              |              7 |           0 |\n",
      "| 15 | Ukraine             |              5 |           0 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View only the columns Team, Yellow Cards and Red Cards\n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\n",
    "\n",
    "# Displays the team discipline performance in tabular format\n",
    "print(\"Team Discipline Performance:\")\n",
    "print(discipline.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efea3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Discipline Performance (Sorted):\n",
      "|    | Team                |   Yellow Cards |   Red Cards |\n",
      "|---:|:--------------------|---------------:|------------:|\n",
      "|  2 | Denmark             |              4 |           0 |\n",
      "|  5 | Germany             |              4 |           0 |\n",
      "|  3 | England             |              5 |           0 |\n",
      "|  8 | Netherlands         |              5 |           0 |\n",
      "| 15 | Ukraine             |              5 |           0 |\n",
      "|  4 | France              |              6 |           0 |\n",
      "| 12 | Russia              |              6 |           0 |\n",
      "|  1 | Czech Republic      |              7 |           0 |\n",
      "| 14 | Sweden              |              7 |           0 |\n",
      "|  0 | Croatia             |              9 |           0 |\n",
      "| 13 | Spain               |             11 |           0 |\n",
      "| 10 | Portugal            |             12 |           0 |\n",
      "|  7 | Italy               |             16 |           0 |\n",
      "| 11 | Republic of Ireland |              6 |           1 |\n",
      "|  9 | Poland              |              7 |           1 |\n",
      "|  6 | Greece              |              9 |           1 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the teams by Red Cards, then Yellow Cards\n",
    "sorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'])\n",
    "\n",
    "# Displays the sorted team discipline performance in tabular format\n",
    "print(\"Team Discipline Performance (Sorted):\")\n",
    "print(sorted_discipline.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc10eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Yellow Cards per Team: \n",
      "| Team                |   Yellow Cards |\n",
      "|:--------------------|---------------:|\n",
      "| Croatia             |              9 |\n",
      "| Czech Republic      |              7 |\n",
      "| Denmark             |              4 |\n",
      "| England             |              5 |\n",
      "| France              |              6 |\n",
      "| Germany             |              4 |\n",
      "| Greece              |              9 |\n",
      "| Italy               |             16 |\n",
      "| Netherlands         |              5 |\n",
      "| Poland              |              7 |\n",
      "| Portugal            |             12 |\n",
      "| Republic of Ireland |              6 |\n",
      "| Russia              |              6 |\n",
      "| Spain               |             11 |\n",
      "| Sweden              |              7 |\n",
      "| Ukraine             |              5 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean Yellow Cards given per Team\n",
    "mean_yellow_cards_per_team = euro12.groupby('Team')['Yellow Cards'].mean().reset_index()\n",
    "\n",
    "# Displays the mean Yellow Cards per Team in tabular format\n",
    "print(\"Mean Yellow Cards per Team: \")\n",
    "print(mean_yellow_cards_per_team.to_markdown(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d615b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams that scored more than 6 goals:\n",
      "| Team    |   Goals |\n",
      "|:--------|--------:|\n",
      "| Germany |      10 |\n",
      "| Spain   |      12 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter teams that scored more than 6 goals\n",
    "high_scoring_teams = euro12[euro12['Goals'] > 6][['Team', 'Goals']]\n",
    "\n",
    "# Displays teams that scored more than 6 goals in tabular format\n",
    "print(\"Teams that scored more than 6 goals:\")\n",
    "print(high_scoring_teams.to_markdown(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da98b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams starting with letter G:\n",
      "| Team    |\n",
      "|:--------|\n",
      "| Germany |\n",
      "| Greece  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Select teams that start with G\n",
    "teams_starting_with_G = euro12[euro12['Team'].str.startswith('G')]['Team']\n",
    "\n",
    "# Displays teams starting with the letter G in tabular format\n",
    "print(\"Teams starting with letter G:\")\n",
    "print(teams_starting_with_G.to_markdown(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5e006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First seven columns:\n",
      "|    | Team                |   Goals |   Shots on target |   Shots off target | Shooting Accuracy   | % Goals-to-shots   |   Total shots (inc. Blocked) |\n",
      "|---:|:--------------------|--------:|------------------:|-------------------:|:--------------------|:-------------------|-----------------------------:|\n",
      "|  0 | Croatia             |       4 |                13 |                 12 | 51.9%               | 16.0%              |                           32 |\n",
      "|  1 | Czech Republic      |       4 |                13 |                 18 | 41.9%               | 12.9%              |                           39 |\n",
      "|  2 | Denmark             |       4 |                10 |                 10 | 50.0%               | 20.0%              |                           27 |\n",
      "|  3 | England             |       5 |                11 |                 18 | 50.0%               | 17.2%              |                           40 |\n",
      "|  4 | France              |       3 |                22 |                 24 | 37.9%               | 6.5%               |                           65 |\n",
      "|  5 | Germany             |      10 |                32 |                 32 | 47.8%               | 15.6%              |                           80 |\n",
      "|  6 | Greece              |       5 |                 8 |                 18 | 30.7%               | 19.2%              |                           32 |\n",
      "|  7 | Italy               |       6 |                34 |                 45 | 43.0%               | 7.5%               |                          110 |\n",
      "|  8 | Netherlands         |       2 |                12 |                 36 | 25.0%               | 4.1%               |                           60 |\n",
      "|  9 | Poland              |       2 |                15 |                 23 | 39.4%               | 5.2%               |                           48 |\n",
      "| 10 | Portugal            |       6 |                22 |                 42 | 34.3%               | 9.3%               |                           82 |\n",
      "| 11 | Republic of Ireland |       1 |                 7 |                 12 | 36.8%               | 5.2%               |                           28 |\n",
      "| 12 | Russia              |       5 |                 9 |                 31 | 22.5%               | 12.5%              |                           59 |\n",
      "| 13 | Spain               |      12 |                42 |                 33 | 55.9%               | 16.0%              |                          100 |\n",
      "| 14 | Sweden              |       5 |                17 |                 19 | 47.2%               | 13.8%              |                           39 |\n",
      "| 15 | Ukraine             |       2 |                 7 |                 26 | 21.2%               | 6.0%               |                           38 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Select the first 7 columns\n",
    "first_7_columns = euro12.iloc[:, :7]\n",
    "\n",
    "# Displays the first 7 columns in tabular format\n",
    "print(\"First seven columns:\")\n",
    "print(first_7_columns.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec00266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns except the last three: \n",
      "                   Team  Goals  Shots on target  Shots off target  \\\n",
      "0               Croatia      4               13                12   \n",
      "1        Czech Republic      4               13                18   \n",
      "2               Denmark      4               10                10   \n",
      "3               England      5               11                18   \n",
      "4                France      3               22                24   \n",
      "5               Germany     10               32                32   \n",
      "6                Greece      5                8                18   \n",
      "7                 Italy      6               34                45   \n",
      "8           Netherlands      2               12                36   \n",
      "9                Poland      2               15                23   \n",
      "10             Portugal      6               22                42   \n",
      "11  Republic of Ireland      1                7                12   \n",
      "12               Russia      5                9                31   \n",
      "13                Spain     12               42                33   \n",
      "14               Sweden      5               17                19   \n",
      "15              Ukraine      2                7                26   \n",
      "\n",
      "   Shooting Accuracy % Goals-to-shots  Total shots (inc. Blocked)  \\\n",
      "0              51.9%            16.0%                          32   \n",
      "1              41.9%            12.9%                          39   \n",
      "2              50.0%            20.0%                          27   \n",
      "3              50.0%            17.2%                          40   \n",
      "4              37.9%             6.5%                          65   \n",
      "5              47.8%            15.6%                          80   \n",
      "6              30.7%            19.2%                          32   \n",
      "7              43.0%             7.5%                         110   \n",
      "8              25.0%             4.1%                          60   \n",
      "9              39.4%             5.2%                          48   \n",
      "10             34.3%             9.3%                          82   \n",
      "11             36.8%             5.2%                          28   \n",
      "12             22.5%            12.5%                          59   \n",
      "13             55.9%            16.0%                         100   \n",
      "14             47.2%            13.8%                          39   \n",
      "15             21.2%             6.0%                          38   \n",
      "\n",
      "    Hit Woodwork  Penalty goals  Penalties not scored  ...  Clean Sheets  \\\n",
      "0              0              0                     0  ...             0   \n",
      "1              0              0                     0  ...             1   \n",
      "2              1              0                     0  ...             1   \n",
      "3              0              0                     0  ...             2   \n",
      "4              1              0                     0  ...             1   \n",
      "5              2              1                     0  ...             1   \n",
      "6              1              1                     1  ...             1   \n",
      "7              2              0                     0  ...             2   \n",
      "8              2              0                     0  ...             0   \n",
      "9              0              0                     0  ...             0   \n",
      "10             6              0                     0  ...             2   \n",
      "11             0              0                     0  ...             0   \n",
      "12             2              0                     0  ...             0   \n",
      "13             0              1                     0  ...             5   \n",
      "14             3              0                     0  ...             1   \n",
      "15             0              0                     0  ...             0   \n",
      "\n",
      "    Blocks  Goals conceded Saves made  Saves-to-shots ratio  Fouls Won  \\\n",
      "0       10               3         13                 81.3%         41   \n",
      "1       10               6          9                 60.1%         53   \n",
      "2       10               5         10                 66.7%         25   \n",
      "3       29               3         22                 88.1%         43   \n",
      "4        7               5          6                 54.6%         36   \n",
      "5       11               6         10                 62.6%         63   \n",
      "6       23               7         13                 65.1%         67   \n",
      "7       18               7         20                 74.1%        101   \n",
      "8        9               5         12                 70.6%         35   \n",
      "9        8               3          6                 66.7%         48   \n",
      "10      11               4         10                 71.5%         73   \n",
      "11      23               9         17                 65.4%         43   \n",
      "12       8               3         10                 77.0%         34   \n",
      "13       8               1         15                 93.8%        102   \n",
      "14      12               5          8                 61.6%         35   \n",
      "15       4               4         13                 76.5%         48   \n",
      "\n",
      "    Fouls Conceded  Offsides  Yellow Cards  Red Cards  \n",
      "0               62         2             9          0  \n",
      "1               73         8             7          0  \n",
      "2               38         8             4          0  \n",
      "3               45         6             5          0  \n",
      "4               51         5             6          0  \n",
      "5               49        12             4          0  \n",
      "6               48        12             9          1  \n",
      "7               89        16            16          0  \n",
      "8               30         3             5          0  \n",
      "9               56         3             7          1  \n",
      "10              90        10            12          0  \n",
      "11              51        11             6          1  \n",
      "12              43         4             6          0  \n",
      "13              83        19            11          0  \n",
      "14              51         7             7          0  \n",
      "15              31         4             5          0  \n",
      "\n",
      "[16 rows x 32 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Select all columns except the last 3\n",
    "all_columns_except_last_3 = euro12.iloc[:, :-3]\n",
    "\n",
    "# Displays all columns except the last 3 in tabular format\n",
    "print(\"All columns except the last three: \")\n",
    "print(all_columns_except_last_3)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9806557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shooting Accuracy for England, Italy, and Russia:\n",
      "|    | Team    | Shooting Accuracy   |\n",
      "|---:|:--------|:--------------------|\n",
      "|  3 | England | 50.0%               |\n",
      "|  7 | Italy   | 43.0%               |\n",
      "| 12 | Russia  | 22.5%               |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Present only the Shooting Accuracy from England, Italy, and Russia\n",
    "selected_teams = ['England', 'Italy', 'Russia']\n",
    "shooting_accuracy_selected_teams = euro12[euro12['Team'].isin(selected_teams)][['Team', 'Shooting Accuracy']]\n",
    "\n",
    "# Displays shooting accuracy for selected teams in tabular format\n",
    "print(\"Shooting Accuracy for England, Italy, and Russia:\")\n",
    "print(shooting_accuracy_selected_teams.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db36f1",
   "metadata": {},
   "source": [
    "<h2>Question 3</h2>\n",
    "Housing<br>\n",
    "Step 1. Import the necessary libraries<br>\n",
    "Step 2. Create 3 differents Series, each of length 100, as follows:<br>\n",
    "<ul>\n",
    "<li>The first a random number from 1 to 4</li>\n",
    "<li>The second a random number from 1 to 3</li>\n",
    "<li>The third a random number from 10,000 to 30,000 </li></ul>\n",
    "Step 3. Create a DataFrame by joinning the Series by column<br>\n",
    "Step 4. Change the name of the columns to bedrs, bathrs, price_sqr_meter<br>\n",
    "Step 5. Create a one column DataFrame with the values of the 3 Series and assign it \n",
    "to 'bigcolumn'<br>\n",
    "Step 6. Ops it seems it is going only until index 99. Is it true? <br>\n",
    "Step 7. Reindex the DataFrame so it goes from 0 to 299<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807c5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Create 3 different Series\n",
    "# Generates Random integers between 1 and 4\n",
    "series1 = pd.Series(np.random.randint(1, 5, size=100))  \n",
    "# Generates Random integers between 1 and 3\n",
    "series2 = pd.Series(np.random.randint(1, 4, size=100))  \n",
    "# Generates Random integers between 10000 and 30000\n",
    "series3 = pd.Series(np.random.randint(10000, 30001, size=100))  \n",
    "\n",
    "#  Create a DataFrame by joining the Series by column\n",
    "data = pd.concat([series1, series2, series3], axis=1)\n",
    "\n",
    "# Change the name of the columns\n",
    "data.columns = ['bedrs', 'bathrs', 'price_sqr_meter']\n",
    "\n",
    "# Step 5: Create a one column DataFrame with the values of the 3 Series\n",
    "bigcolumn = pd.concat([series1, series2, series3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d860634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the DataFrame go only until index 99? False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Check if the DataFrame goes only until index 99\n",
    "print(\"Does the DataFrame go only until index 99?\", bigcolumn.index.max() == 99)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5291bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data DataFrame:\n",
      "+----+---------+----------+-------------------+\n",
      "|    |   bedrs |   bathrs |   price_sqr_meter |\n",
      "+====+=========+==========+===================+\n",
      "|  0 |       4 |        2 |             29873 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  1 |       1 |        1 |             14811 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  2 |       2 |        3 |             23604 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  3 |       2 |        2 |             17145 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  4 |       3 |        1 |             17690 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  5 |       4 |        1 |             28058 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  6 |       1 |        3 |             14547 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  7 |       1 |        1 |             20291 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  8 |       1 |        1 |             25060 |\n",
      "+----+---------+----------+-------------------+\n",
      "|  9 |       4 |        3 |             29422 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 10 |       4 |        1 |             16609 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 11 |       1 |        3 |             22948 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 12 |       2 |        2 |             15794 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 13 |       2 |        1 |             13080 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 14 |       1 |        3 |             11959 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 15 |       2 |        3 |             23822 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 16 |       1 |        2 |             25087 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 17 |       2 |        2 |             18064 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 18 |       4 |        3 |             19507 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 19 |       1 |        2 |             22092 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 20 |       2 |        2 |             14498 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 21 |       2 |        3 |             10861 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 22 |       2 |        3 |             28329 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 23 |       1 |        2 |             20183 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 24 |       4 |        3 |             27343 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 25 |       3 |        3 |             28971 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 26 |       1 |        3 |             20274 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 27 |       4 |        1 |             16193 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 28 |       2 |        1 |             25809 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 29 |       2 |        3 |             23270 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 30 |       4 |        2 |             11149 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 31 |       3 |        3 |             21999 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 32 |       2 |        1 |             26640 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 33 |       3 |        3 |             23690 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 34 |       1 |        2 |             13876 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 35 |       2 |        2 |             29008 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 36 |       2 |        1 |             24774 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 37 |       2 |        2 |             18943 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 38 |       3 |        3 |             20211 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 39 |       3 |        1 |             12358 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 40 |       4 |        3 |             15638 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 41 |       4 |        3 |             18629 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 42 |       3 |        1 |             15852 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 43 |       4 |        2 |             19863 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 44 |       1 |        1 |             14884 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 45 |       1 |        3 |             27831 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 46 |       2 |        2 |             27259 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 47 |       4 |        2 |             14290 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 48 |       1 |        2 |             26144 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 49 |       4 |        3 |             25636 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 50 |       1 |        1 |             19502 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 51 |       1 |        1 |             13260 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 52 |       2 |        1 |             20784 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 53 |       2 |        1 |             16397 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 54 |       1 |        2 |             14127 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 55 |       3 |        1 |             12515 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 56 |       2 |        2 |             29782 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 57 |       4 |        1 |             19202 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 58 |       2 |        1 |             13280 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 59 |       4 |        2 |             22024 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 60 |       1 |        1 |             11819 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 61 |       3 |        3 |             24597 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 62 |       4 |        1 |             12558 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 63 |       4 |        2 |             27861 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 64 |       1 |        1 |             23183 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 65 |       1 |        2 |             28093 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 66 |       1 |        1 |             22676 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 67 |       2 |        1 |             16683 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 68 |       4 |        2 |             29126 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 69 |       3 |        1 |             22367 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 70 |       2 |        1 |             17896 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 71 |       3 |        1 |             26139 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 72 |       4 |        3 |             14587 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 73 |       4 |        1 |             11801 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 74 |       4 |        1 |             28536 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 75 |       1 |        1 |             15764 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 76 |       4 |        3 |             21227 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 77 |       1 |        1 |             12767 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 78 |       4 |        3 |             11962 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 79 |       1 |        1 |             14524 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 80 |       2 |        3 |             21378 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 81 |       1 |        1 |             22803 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 82 |       1 |        3 |             18734 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 83 |       2 |        3 |             23743 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 84 |       1 |        3 |             20454 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 85 |       2 |        1 |             23544 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 86 |       3 |        2 |             24980 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 87 |       3 |        3 |             16736 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 88 |       2 |        1 |             12243 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 89 |       4 |        2 |             24984 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 90 |       3 |        2 |             28286 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 91 |       2 |        1 |             21085 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 92 |       4 |        3 |             25965 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 93 |       3 |        3 |             24583 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 94 |       2 |        2 |             22474 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 95 |       1 |        3 |             23225 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 96 |       3 |        1 |             17038 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 97 |       1 |        3 |             24839 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 98 |       2 |        1 |             26161 |\n",
      "+----+---------+----------+-------------------+\n",
      "| 99 |       2 |        2 |             23848 |\n",
      "+----+---------+----------+-------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Reindex the DataFrame so it goes from 0 to 299\n",
    "bigcolumn = bigcolumn.reindex(range(300))\n",
    "\n",
    "# Prints the DataFrames using tabulate\n",
    "print(\"Data DataFrame:\")\n",
    "print(tabulate(data, headers='keys', tablefmt='grid'))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1099b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigcolumn DataFrame:\n",
      "+-----+-------+\n",
      "|     |     0 |\n",
      "+=====+=======+\n",
      "|   0 |     4 |\n",
      "+-----+-------+\n",
      "|   1 |     1 |\n",
      "+-----+-------+\n",
      "|   2 |     2 |\n",
      "+-----+-------+\n",
      "|   3 |     2 |\n",
      "+-----+-------+\n",
      "|   4 |     3 |\n",
      "+-----+-------+\n",
      "|   5 |     4 |\n",
      "+-----+-------+\n",
      "|   6 |     1 |\n",
      "+-----+-------+\n",
      "|   7 |     1 |\n",
      "+-----+-------+\n",
      "|   8 |     1 |\n",
      "+-----+-------+\n",
      "|   9 |     4 |\n",
      "+-----+-------+\n",
      "|  10 |     4 |\n",
      "+-----+-------+\n",
      "|  11 |     1 |\n",
      "+-----+-------+\n",
      "|  12 |     2 |\n",
      "+-----+-------+\n",
      "|  13 |     2 |\n",
      "+-----+-------+\n",
      "|  14 |     1 |\n",
      "+-----+-------+\n",
      "|  15 |     2 |\n",
      "+-----+-------+\n",
      "|  16 |     1 |\n",
      "+-----+-------+\n",
      "|  17 |     2 |\n",
      "+-----+-------+\n",
      "|  18 |     4 |\n",
      "+-----+-------+\n",
      "|  19 |     1 |\n",
      "+-----+-------+\n",
      "|  20 |     2 |\n",
      "+-----+-------+\n",
      "|  21 |     2 |\n",
      "+-----+-------+\n",
      "|  22 |     2 |\n",
      "+-----+-------+\n",
      "|  23 |     1 |\n",
      "+-----+-------+\n",
      "|  24 |     4 |\n",
      "+-----+-------+\n",
      "|  25 |     3 |\n",
      "+-----+-------+\n",
      "|  26 |     1 |\n",
      "+-----+-------+\n",
      "|  27 |     4 |\n",
      "+-----+-------+\n",
      "|  28 |     2 |\n",
      "+-----+-------+\n",
      "|  29 |     2 |\n",
      "+-----+-------+\n",
      "|  30 |     4 |\n",
      "+-----+-------+\n",
      "|  31 |     3 |\n",
      "+-----+-------+\n",
      "|  32 |     2 |\n",
      "+-----+-------+\n",
      "|  33 |     3 |\n",
      "+-----+-------+\n",
      "|  34 |     1 |\n",
      "+-----+-------+\n",
      "|  35 |     2 |\n",
      "+-----+-------+\n",
      "|  36 |     2 |\n",
      "+-----+-------+\n",
      "|  37 |     2 |\n",
      "+-----+-------+\n",
      "|  38 |     3 |\n",
      "+-----+-------+\n",
      "|  39 |     3 |\n",
      "+-----+-------+\n",
      "|  40 |     4 |\n",
      "+-----+-------+\n",
      "|  41 |     4 |\n",
      "+-----+-------+\n",
      "|  42 |     3 |\n",
      "+-----+-------+\n",
      "|  43 |     4 |\n",
      "+-----+-------+\n",
      "|  44 |     1 |\n",
      "+-----+-------+\n",
      "|  45 |     1 |\n",
      "+-----+-------+\n",
      "|  46 |     2 |\n",
      "+-----+-------+\n",
      "|  47 |     4 |\n",
      "+-----+-------+\n",
      "|  48 |     1 |\n",
      "+-----+-------+\n",
      "|  49 |     4 |\n",
      "+-----+-------+\n",
      "|  50 |     1 |\n",
      "+-----+-------+\n",
      "|  51 |     1 |\n",
      "+-----+-------+\n",
      "|  52 |     2 |\n",
      "+-----+-------+\n",
      "|  53 |     2 |\n",
      "+-----+-------+\n",
      "|  54 |     1 |\n",
      "+-----+-------+\n",
      "|  55 |     3 |\n",
      "+-----+-------+\n",
      "|  56 |     2 |\n",
      "+-----+-------+\n",
      "|  57 |     4 |\n",
      "+-----+-------+\n",
      "|  58 |     2 |\n",
      "+-----+-------+\n",
      "|  59 |     4 |\n",
      "+-----+-------+\n",
      "|  60 |     1 |\n",
      "+-----+-------+\n",
      "|  61 |     3 |\n",
      "+-----+-------+\n",
      "|  62 |     4 |\n",
      "+-----+-------+\n",
      "|  63 |     4 |\n",
      "+-----+-------+\n",
      "|  64 |     1 |\n",
      "+-----+-------+\n",
      "|  65 |     1 |\n",
      "+-----+-------+\n",
      "|  66 |     1 |\n",
      "+-----+-------+\n",
      "|  67 |     2 |\n",
      "+-----+-------+\n",
      "|  68 |     4 |\n",
      "+-----+-------+\n",
      "|  69 |     3 |\n",
      "+-----+-------+\n",
      "|  70 |     2 |\n",
      "+-----+-------+\n",
      "|  71 |     3 |\n",
      "+-----+-------+\n",
      "|  72 |     4 |\n",
      "+-----+-------+\n",
      "|  73 |     4 |\n",
      "+-----+-------+\n",
      "|  74 |     4 |\n",
      "+-----+-------+\n",
      "|  75 |     1 |\n",
      "+-----+-------+\n",
      "|  76 |     4 |\n",
      "+-----+-------+\n",
      "|  77 |     1 |\n",
      "+-----+-------+\n",
      "|  78 |     4 |\n",
      "+-----+-------+\n",
      "|  79 |     1 |\n",
      "+-----+-------+\n",
      "|  80 |     2 |\n",
      "+-----+-------+\n",
      "|  81 |     1 |\n",
      "+-----+-------+\n",
      "|  82 |     1 |\n",
      "+-----+-------+\n",
      "|  83 |     2 |\n",
      "+-----+-------+\n",
      "|  84 |     1 |\n",
      "+-----+-------+\n",
      "|  85 |     2 |\n",
      "+-----+-------+\n",
      "|  86 |     3 |\n",
      "+-----+-------+\n",
      "|  87 |     3 |\n",
      "+-----+-------+\n",
      "|  88 |     2 |\n",
      "+-----+-------+\n",
      "|  89 |     4 |\n",
      "+-----+-------+\n",
      "|  90 |     3 |\n",
      "+-----+-------+\n",
      "|  91 |     2 |\n",
      "+-----+-------+\n",
      "|  92 |     4 |\n",
      "+-----+-------+\n",
      "|  93 |     3 |\n",
      "+-----+-------+\n",
      "|  94 |     2 |\n",
      "+-----+-------+\n",
      "|  95 |     1 |\n",
      "+-----+-------+\n",
      "|  96 |     3 |\n",
      "+-----+-------+\n",
      "|  97 |     1 |\n",
      "+-----+-------+\n",
      "|  98 |     2 |\n",
      "+-----+-------+\n",
      "|  99 |     2 |\n",
      "+-----+-------+\n",
      "| 100 |     2 |\n",
      "+-----+-------+\n",
      "| 101 |     1 |\n",
      "+-----+-------+\n",
      "| 102 |     3 |\n",
      "+-----+-------+\n",
      "| 103 |     2 |\n",
      "+-----+-------+\n",
      "| 104 |     1 |\n",
      "+-----+-------+\n",
      "| 105 |     1 |\n",
      "+-----+-------+\n",
      "| 106 |     3 |\n",
      "+-----+-------+\n",
      "| 107 |     1 |\n",
      "+-----+-------+\n",
      "| 108 |     1 |\n",
      "+-----+-------+\n",
      "| 109 |     3 |\n",
      "+-----+-------+\n",
      "| 110 |     1 |\n",
      "+-----+-------+\n",
      "| 111 |     3 |\n",
      "+-----+-------+\n",
      "| 112 |     2 |\n",
      "+-----+-------+\n",
      "| 113 |     1 |\n",
      "+-----+-------+\n",
      "| 114 |     3 |\n",
      "+-----+-------+\n",
      "| 115 |     3 |\n",
      "+-----+-------+\n",
      "| 116 |     2 |\n",
      "+-----+-------+\n",
      "| 117 |     2 |\n",
      "+-----+-------+\n",
      "| 118 |     3 |\n",
      "+-----+-------+\n",
      "| 119 |     2 |\n",
      "+-----+-------+\n",
      "| 120 |     2 |\n",
      "+-----+-------+\n",
      "| 121 |     3 |\n",
      "+-----+-------+\n",
      "| 122 |     3 |\n",
      "+-----+-------+\n",
      "| 123 |     2 |\n",
      "+-----+-------+\n",
      "| 124 |     3 |\n",
      "+-----+-------+\n",
      "| 125 |     3 |\n",
      "+-----+-------+\n",
      "| 126 |     3 |\n",
      "+-----+-------+\n",
      "| 127 |     1 |\n",
      "+-----+-------+\n",
      "| 128 |     1 |\n",
      "+-----+-------+\n",
      "| 129 |     3 |\n",
      "+-----+-------+\n",
      "| 130 |     2 |\n",
      "+-----+-------+\n",
      "| 131 |     3 |\n",
      "+-----+-------+\n",
      "| 132 |     1 |\n",
      "+-----+-------+\n",
      "| 133 |     3 |\n",
      "+-----+-------+\n",
      "| 134 |     2 |\n",
      "+-----+-------+\n",
      "| 135 |     2 |\n",
      "+-----+-------+\n",
      "| 136 |     1 |\n",
      "+-----+-------+\n",
      "| 137 |     2 |\n",
      "+-----+-------+\n",
      "| 138 |     3 |\n",
      "+-----+-------+\n",
      "| 139 |     1 |\n",
      "+-----+-------+\n",
      "| 140 |     3 |\n",
      "+-----+-------+\n",
      "| 141 |     3 |\n",
      "+-----+-------+\n",
      "| 142 |     1 |\n",
      "+-----+-------+\n",
      "| 143 |     2 |\n",
      "+-----+-------+\n",
      "| 144 |     1 |\n",
      "+-----+-------+\n",
      "| 145 |     3 |\n",
      "+-----+-------+\n",
      "| 146 |     2 |\n",
      "+-----+-------+\n",
      "| 147 |     2 |\n",
      "+-----+-------+\n",
      "| 148 |     2 |\n",
      "+-----+-------+\n",
      "| 149 |     3 |\n",
      "+-----+-------+\n",
      "| 150 |     1 |\n",
      "+-----+-------+\n",
      "| 151 |     1 |\n",
      "+-----+-------+\n",
      "| 152 |     1 |\n",
      "+-----+-------+\n",
      "| 153 |     1 |\n",
      "+-----+-------+\n",
      "| 154 |     2 |\n",
      "+-----+-------+\n",
      "| 155 |     1 |\n",
      "+-----+-------+\n",
      "| 156 |     2 |\n",
      "+-----+-------+\n",
      "| 157 |     1 |\n",
      "+-----+-------+\n",
      "| 158 |     1 |\n",
      "+-----+-------+\n",
      "| 159 |     2 |\n",
      "+-----+-------+\n",
      "| 160 |     1 |\n",
      "+-----+-------+\n",
      "| 161 |     3 |\n",
      "+-----+-------+\n",
      "| 162 |     1 |\n",
      "+-----+-------+\n",
      "| 163 |     2 |\n",
      "+-----+-------+\n",
      "| 164 |     1 |\n",
      "+-----+-------+\n",
      "| 165 |     2 |\n",
      "+-----+-------+\n",
      "| 166 |     1 |\n",
      "+-----+-------+\n",
      "| 167 |     1 |\n",
      "+-----+-------+\n",
      "| 168 |     2 |\n",
      "+-----+-------+\n",
      "| 169 |     1 |\n",
      "+-----+-------+\n",
      "| 170 |     1 |\n",
      "+-----+-------+\n",
      "| 171 |     1 |\n",
      "+-----+-------+\n",
      "| 172 |     3 |\n",
      "+-----+-------+\n",
      "| 173 |     1 |\n",
      "+-----+-------+\n",
      "| 174 |     1 |\n",
      "+-----+-------+\n",
      "| 175 |     1 |\n",
      "+-----+-------+\n",
      "| 176 |     3 |\n",
      "+-----+-------+\n",
      "| 177 |     1 |\n",
      "+-----+-------+\n",
      "| 178 |     3 |\n",
      "+-----+-------+\n",
      "| 179 |     1 |\n",
      "+-----+-------+\n",
      "| 180 |     3 |\n",
      "+-----+-------+\n",
      "| 181 |     1 |\n",
      "+-----+-------+\n",
      "| 182 |     3 |\n",
      "+-----+-------+\n",
      "| 183 |     3 |\n",
      "+-----+-------+\n",
      "| 184 |     3 |\n",
      "+-----+-------+\n",
      "| 185 |     1 |\n",
      "+-----+-------+\n",
      "| 186 |     2 |\n",
      "+-----+-------+\n",
      "| 187 |     3 |\n",
      "+-----+-------+\n",
      "| 188 |     1 |\n",
      "+-----+-------+\n",
      "| 189 |     2 |\n",
      "+-----+-------+\n",
      "| 190 |     2 |\n",
      "+-----+-------+\n",
      "| 191 |     1 |\n",
      "+-----+-------+\n",
      "| 192 |     3 |\n",
      "+-----+-------+\n",
      "| 193 |     3 |\n",
      "+-----+-------+\n",
      "| 194 |     2 |\n",
      "+-----+-------+\n",
      "| 195 |     3 |\n",
      "+-----+-------+\n",
      "| 196 |     1 |\n",
      "+-----+-------+\n",
      "| 197 |     3 |\n",
      "+-----+-------+\n",
      "| 198 |     1 |\n",
      "+-----+-------+\n",
      "| 199 |     2 |\n",
      "+-----+-------+\n",
      "| 200 | 29873 |\n",
      "+-----+-------+\n",
      "| 201 | 14811 |\n",
      "+-----+-------+\n",
      "| 202 | 23604 |\n",
      "+-----+-------+\n",
      "| 203 | 17145 |\n",
      "+-----+-------+\n",
      "| 204 | 17690 |\n",
      "+-----+-------+\n",
      "| 205 | 28058 |\n",
      "+-----+-------+\n",
      "| 206 | 14547 |\n",
      "+-----+-------+\n",
      "| 207 | 20291 |\n",
      "+-----+-------+\n",
      "| 208 | 25060 |\n",
      "+-----+-------+\n",
      "| 209 | 29422 |\n",
      "+-----+-------+\n",
      "| 210 | 16609 |\n",
      "+-----+-------+\n",
      "| 211 | 22948 |\n",
      "+-----+-------+\n",
      "| 212 | 15794 |\n",
      "+-----+-------+\n",
      "| 213 | 13080 |\n",
      "+-----+-------+\n",
      "| 214 | 11959 |\n",
      "+-----+-------+\n",
      "| 215 | 23822 |\n",
      "+-----+-------+\n",
      "| 216 | 25087 |\n",
      "+-----+-------+\n",
      "| 217 | 18064 |\n",
      "+-----+-------+\n",
      "| 218 | 19507 |\n",
      "+-----+-------+\n",
      "| 219 | 22092 |\n",
      "+-----+-------+\n",
      "| 220 | 14498 |\n",
      "+-----+-------+\n",
      "| 221 | 10861 |\n",
      "+-----+-------+\n",
      "| 222 | 28329 |\n",
      "+-----+-------+\n",
      "| 223 | 20183 |\n",
      "+-----+-------+\n",
      "| 224 | 27343 |\n",
      "+-----+-------+\n",
      "| 225 | 28971 |\n",
      "+-----+-------+\n",
      "| 226 | 20274 |\n",
      "+-----+-------+\n",
      "| 227 | 16193 |\n",
      "+-----+-------+\n",
      "| 228 | 25809 |\n",
      "+-----+-------+\n",
      "| 229 | 23270 |\n",
      "+-----+-------+\n",
      "| 230 | 11149 |\n",
      "+-----+-------+\n",
      "| 231 | 21999 |\n",
      "+-----+-------+\n",
      "| 232 | 26640 |\n",
      "+-----+-------+\n",
      "| 233 | 23690 |\n",
      "+-----+-------+\n",
      "| 234 | 13876 |\n",
      "+-----+-------+\n",
      "| 235 | 29008 |\n",
      "+-----+-------+\n",
      "| 236 | 24774 |\n",
      "+-----+-------+\n",
      "| 237 | 18943 |\n",
      "+-----+-------+\n",
      "| 238 | 20211 |\n",
      "+-----+-------+\n",
      "| 239 | 12358 |\n",
      "+-----+-------+\n",
      "| 240 | 15638 |\n",
      "+-----+-------+\n",
      "| 241 | 18629 |\n",
      "+-----+-------+\n",
      "| 242 | 15852 |\n",
      "+-----+-------+\n",
      "| 243 | 19863 |\n",
      "+-----+-------+\n",
      "| 244 | 14884 |\n",
      "+-----+-------+\n",
      "| 245 | 27831 |\n",
      "+-----+-------+\n",
      "| 246 | 27259 |\n",
      "+-----+-------+\n",
      "| 247 | 14290 |\n",
      "+-----+-------+\n",
      "| 248 | 26144 |\n",
      "+-----+-------+\n",
      "| 249 | 25636 |\n",
      "+-----+-------+\n",
      "| 250 | 19502 |\n",
      "+-----+-------+\n",
      "| 251 | 13260 |\n",
      "+-----+-------+\n",
      "| 252 | 20784 |\n",
      "+-----+-------+\n",
      "| 253 | 16397 |\n",
      "+-----+-------+\n",
      "| 254 | 14127 |\n",
      "+-----+-------+\n",
      "| 255 | 12515 |\n",
      "+-----+-------+\n",
      "| 256 | 29782 |\n",
      "+-----+-------+\n",
      "| 257 | 19202 |\n",
      "+-----+-------+\n",
      "| 258 | 13280 |\n",
      "+-----+-------+\n",
      "| 259 | 22024 |\n",
      "+-----+-------+\n",
      "| 260 | 11819 |\n",
      "+-----+-------+\n",
      "| 261 | 24597 |\n",
      "+-----+-------+\n",
      "| 262 | 12558 |\n",
      "+-----+-------+\n",
      "| 263 | 27861 |\n",
      "+-----+-------+\n",
      "| 264 | 23183 |\n",
      "+-----+-------+\n",
      "| 265 | 28093 |\n",
      "+-----+-------+\n",
      "| 266 | 22676 |\n",
      "+-----+-------+\n",
      "| 267 | 16683 |\n",
      "+-----+-------+\n",
      "| 268 | 29126 |\n",
      "+-----+-------+\n",
      "| 269 | 22367 |\n",
      "+-----+-------+\n",
      "| 270 | 17896 |\n",
      "+-----+-------+\n",
      "| 271 | 26139 |\n",
      "+-----+-------+\n",
      "| 272 | 14587 |\n",
      "+-----+-------+\n",
      "| 273 | 11801 |\n",
      "+-----+-------+\n",
      "| 274 | 28536 |\n",
      "+-----+-------+\n",
      "| 275 | 15764 |\n",
      "+-----+-------+\n",
      "| 276 | 21227 |\n",
      "+-----+-------+\n",
      "| 277 | 12767 |\n",
      "+-----+-------+\n",
      "| 278 | 11962 |\n",
      "+-----+-------+\n",
      "| 279 | 14524 |\n",
      "+-----+-------+\n",
      "| 280 | 21378 |\n",
      "+-----+-------+\n",
      "| 281 | 22803 |\n",
      "+-----+-------+\n",
      "| 282 | 18734 |\n",
      "+-----+-------+\n",
      "| 283 | 23743 |\n",
      "+-----+-------+\n",
      "| 284 | 20454 |\n",
      "+-----+-------+\n",
      "| 285 | 23544 |\n",
      "+-----+-------+\n",
      "| 286 | 24980 |\n",
      "+-----+-------+\n",
      "| 287 | 16736 |\n",
      "+-----+-------+\n",
      "| 288 | 12243 |\n",
      "+-----+-------+\n",
      "| 289 | 24984 |\n",
      "+-----+-------+\n",
      "| 290 | 28286 |\n",
      "+-----+-------+\n",
      "| 291 | 21085 |\n",
      "+-----+-------+\n",
      "| 292 | 25965 |\n",
      "+-----+-------+\n",
      "| 293 | 24583 |\n",
      "+-----+-------+\n",
      "| 294 | 22474 |\n",
      "+-----+-------+\n",
      "| 295 | 23225 |\n",
      "+-----+-------+\n",
      "| 296 | 17038 |\n",
      "+-----+-------+\n",
      "| 297 | 24839 |\n",
      "+-----+-------+\n",
      "| 298 | 26161 |\n",
      "+-----+-------+\n",
      "| 299 | 23848 |\n",
      "+-----+-------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigcolumn DataFrame:\")\n",
    "print(tabulate(bigcolumn.to_frame(), headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71424e2b",
   "metadata": {},
   "source": [
    "<h2>Question 4</h2>\n",
    "Wind Statistics<br>\n",
    "The data have been modified to contain some missing values, identified by NaN. \n",
    "Using pandas should make this exercise easier, in particular for the bonus question.<br>\n",
    "You should be able to perform all of these operations without using a for loop or \n",
    "other looping construct.<br>\n",
    "The data in 'wind.data' has the following format:<br>\n",
    "Yr Mo Dy RPT VAL ROS KIL SHA BIR DUB CLA MUL CLO BEL \n",
    "MAL<br>\n",
    "61 1 1 15.04 14.96 13.17 9.29 NaN 9.87 13.67 10.25 10.83 12.58 18.50 15.04<br>\n",
    "61 1 2 14.71 NaN 10.83 6.50 12.62 7.67 11.50 10.04 9.79 9.67 17.54 13.83<br>\n",
    "61 1 3 18.50 16.88 12.33 10.13 11.17 6.17 11.25 NaN 8.50 7.67 12.75 12.71<br>\n",
    "\n",
    "The first three columns are year, month, and day. The remaining 12 columns are \n",
    "average windspeeds in knots at 12 locations in Ireland on that day.<br>\n",
    "Step 1. Import the necessary libraries<br>\n",
    "Step 2. Import the dataset from the attached file wind.txt<br>\n",
    "Step 3. Assign it to a variable called data and replace the first 3 columns by a proper \n",
    "datetime index.<br>\n",
    "Step 4. Year 2061? Do we really have data from this year? Create a function to fix it \n",
    "and apply it.<br>\n",
    "Step 5. Set the right dates as the index. Pay attention at the data type, it should be \n",
    "datetime64[ns].<br>\n",
    "Step 6. Compute how many values are missing for each location over the entire \n",
    "record.They should be ignored in all calculations below.<br>\n",
    "Step 7. Compute how many non-missing values there are in total.<br>\n",
    "Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and \n",
    "all the times.<br>\n",
    "A single number for the entire dataset.<br>\n",
    "Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean \n",
    "windspeeds and standard deviations of the windspeeds at each location over all the \n",
    "days\n",
    "A different set of numbers for each location.\n",
    "<br>Step 10. Create a DataFrame called day_stats and calculate the min, max and mean \n",
    "windspeed and standard deviations of the windspeeds across all the locations at each \n",
    "day.\n",
    "A different set of numbers for each day.<br>\n",
    "Step 11. Find the average windspeed in January for each location. \n",
    "Treat January 1961 and January 1962 both as January.<br>\n",
    "Step 12. Downsample the record to a yearly frequency for each location. <br>\n",
    "Step 13. Downsample the record to a monthly frequency for each location. <br>\n",
    "Step 14. Downsample the record to a weekly frequency for each location.<br>\n",
    "Step 15. Calculate the min, max and mean windspeeds and standard deviations of the \n",
    "windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aec5715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"wind.txt\", sep=\" \")\n",
    "\n",
    "# Define a function to fix year values\n",
    "def fix_year(year):\n",
    "    if year >= 90:\n",
    "        return 1900 + year\n",
    "    else:\n",
    "        return 2000 + year\n",
    "\n",
    "# Apply the fix_year function to the 'Yr' column\n",
    "data['Yr'] = data['Yr'].apply(fix_year)\n",
    "\n",
    "#  Rename columns\n",
    "data = data.rename(columns={'Yr': 'year', 'Mo': 'month', 'Dy': 'day'})\n",
    "\n",
    "#  Create a new 'date' column by combining year, month, and day columns\n",
    "data['date'] = pd.to_datetime(data[['year', 'month', 'day']])\n",
    "\n",
    "# Set the 'date' column as the index\n",
    "data.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48887946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "       year  month  day  Unnamed: 3  Unnamed: 4    RPT  Unnamed: 6  Unnamed: 7  \\\n",
      "date                                                                            \n",
      "NaT   2061    NaN  1.0         NaN         1.0  15.04       14.96       13.17   \n",
      "NaT   2061    NaN  1.0         NaN         2.0  14.71         NaN         NaN   \n",
      "NaT   2061    NaN  1.0         NaN         3.0  18.50       16.88       12.33   \n",
      "NaT   2061    NaN  1.0         NaN         4.0  10.58         NaN        6.63   \n",
      "NaT   2061    NaN  1.0         NaN         5.0  13.33       13.25       11.42   \n",
      "\n",
      "        VAL  Unnamed: 9  ...  MUL  Unnamed: 30  Unnamed: 31  CLO  Unnamed: 33  \\\n",
      "date                     ...                                                    \n",
      "NaT     NaN        9.29  ...  NaN          NaN          NaN  NaN          NaN   \n",
      "NaT     NaN       10.83  ...  NaN          NaN          NaN  NaN          NaN   \n",
      "NaT   10.13       11.17  ...  NaN          NaN          NaN  NaN          NaN   \n",
      "NaT   11.75         NaN  ...  NaN          NaN          NaN  NaN          NaN   \n",
      "NaT     NaN        6.17  ...  NaN          NaN          NaN  NaN          NaN   \n",
      "\n",
      "      Unnamed: 34  BEL  Unnamed: 36  Unnamed: 37  MAL  \n",
      "date                                                   \n",
      "NaT           NaN  NaN          NaN          NaN  NaN  \n",
      "NaT           NaN  NaN          NaN          NaN  NaN  \n",
      "NaT           NaN  NaN          NaN          NaN  NaN  \n",
      "NaT           NaN  NaN          NaN          NaN  NaN  \n",
      "NaT           NaN  NaN          NaN          NaN  NaN  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "082c96a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count Per Location:\n",
      "year              0\n",
      "month          4918\n",
      "day             486\n",
      "Unnamed: 3     1831\n",
      "Unnamed: 4     1667\n",
      "RPT            1625\n",
      "Unnamed: 6     2256\n",
      "Unnamed: 7     2478\n",
      "VAL            2432\n",
      "Unnamed: 9     2101\n",
      "Unnamed: 10    2575\n",
      "ROS            2152\n",
      "Unnamed: 12    2393\n",
      "Unnamed: 13    2143\n",
      "KIL            2331\n",
      "Unnamed: 15    2221\n",
      "Unnamed: 16    2985\n",
      "SHA            3204\n",
      "Unnamed: 18    3687\n",
      "Unnamed: 19    3732\n",
      "BIR            4065\n",
      "Unnamed: 21    4078\n",
      "Unnamed: 22    4462\n",
      "DUB            4416\n",
      "Unnamed: 24    4817\n",
      "Unnamed: 25    5032\n",
      "CLA            5590\n",
      "Unnamed: 27    5963\n",
      "Unnamed: 28    6428\n",
      "MUL            6574\n",
      "Unnamed: 30    6573\n",
      "Unnamed: 31    6574\n",
      "CLO            6574\n",
      "Unnamed: 33    6574\n",
      "Unnamed: 34    6574\n",
      "BEL            6574\n",
      "Unnamed: 36    6574\n",
      "Unnamed: 37    6574\n",
      "MAL            6574\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values for each location\n",
    "missing_values_per_location = data.isnull().sum()\n",
    "\n",
    "#  Display the missing values count\n",
    "print(\"Missing Values Count Per Location:\")\n",
    "print(missing_values_per_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed03905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Non-Missing Values: 98579\n"
     ]
    }
   ],
   "source": [
    "#  Count non-missing values in the entire dataset\n",
    "total_non_missing_values = data.notnull().sum().sum()\n",
    "\n",
    "#  Display the total number of non-missing values\n",
    "print(\"Total Number of Non-Missing Values:\", total_non_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf2579db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Windspeed Over All Locations and Times: 78.53632829425008\n"
     ]
    }
   ],
   "source": [
    "#  Calculate the mean windspeed over all locations and times\n",
    "mean_windspeed = data.mean().mean()\n",
    "\n",
    "#  Display the mean windspeed\n",
    "print(\"Mean Windspeed Over All Locations and Times:\", mean_windspeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c08a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Windspeed at Each Location:\n",
      "                 min      max         mean       std\n",
      "year         2061.00  2078.00  2069.500304  5.188131\n",
      "month          10.00    12.00    11.000000  0.821170\n",
      "day             1.00    31.00     7.960578  7.025155\n",
      "Unnamed: 3      1.00    32.96    17.997723  7.320219\n",
      "Unnamed: 4      1.00    35.38    11.769851  6.146505\n",
      "RPT             0.67    35.80    12.415559  5.229848\n",
      "Unnamed: 6      0.21    32.75    11.842916  4.940703\n",
      "Unnamed: 7      0.42    30.37     9.967187  4.911509\n",
      "VAL             0.33    37.54    10.106519  4.953028\n",
      "Unnamed: 9      0.25    32.42    10.079287  4.583270\n",
      "Unnamed: 10     0.00    30.37     9.848580  5.254887\n",
      "ROS             0.08    31.08     9.175468  5.175858\n",
      "Unnamed: 12     0.13    28.21     9.901736  4.674471\n",
      "Unnamed: 13     0.04    38.96     9.994572  5.011803\n",
      "KIL             0.00    42.38    10.897985  6.676379\n",
      "Unnamed: 15     0.00    42.54    10.921328  7.623103\n",
      "Unnamed: 16     0.00    35.13    10.658755  6.660911\n",
      "SHA             0.25    37.99     9.439496  5.788945\n",
      "Unnamed: 18     0.00    41.46     9.127191  5.524925\n",
      "Unnamed: 19     0.04    33.66     8.309641  5.358097\n",
      "BIR             0.00    35.50     8.548127  5.315896\n",
      "Unnamed: 21     0.29    33.17     8.132188  5.180466\n",
      "Unnamed: 22     0.04    33.04     8.451222  5.071942\n",
      "DUB             0.04    34.08     8.168874  4.968116\n",
      "Unnamed: 24     0.13    25.54     9.439585  4.574218\n",
      "Unnamed: 25     0.13    25.00     9.420863  4.048751\n",
      "CLA             0.58    26.25     9.240346  3.623705\n",
      "Unnamed: 27     2.04    27.88     7.857807  3.134903\n",
      "Unnamed: 28     2.21     9.96     6.706164  1.947997\n",
      "MUL              NaN      NaN          NaN       NaN\n",
      "Unnamed: 30     9.21     9.21     9.210000       NaN\n",
      "Unnamed: 31      NaN      NaN          NaN       NaN\n",
      "CLO              NaN      NaN          NaN       NaN\n",
      "Unnamed: 33      NaN      NaN          NaN       NaN\n",
      "Unnamed: 34      NaN      NaN          NaN       NaN\n",
      "BEL              NaN      NaN          NaN       NaN\n",
      "Unnamed: 36      NaN      NaN          NaN       NaN\n",
      "Unnamed: 37      NaN      NaN          NaN       NaN\n",
      "MAL              NaN      NaN          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#  Calculate statistics for each location\n",
    "loc_stats = pd.DataFrame({\n",
    "    'min': data.min(),\n",
    "    'max': data.max(),\n",
    "    'mean': data.mean(),\n",
    "    'std': data.std()\n",
    "})\n",
    "\n",
    "#  Display the loc_stats DataFrame\n",
    "print(\"Statistics for Windspeed at Each Location:\")\n",
    "print(loc_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df368b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Windspeed Across All Locations Each Day:\n",
      "              RPT                      VAL                      ROS         \\\n",
      "              min    max   mean std    min    max   mean std    min    max   \n",
      "date                                                                         \n",
      "2061-10-10  11.46  11.46  11.46 NaN  13.17  13.17  13.17 NaN  12.38  12.38   \n",
      "2061-10-11  10.13  10.13  10.13 NaN  13.54  13.54  13.54 NaN  12.71  12.71   \n",
      "2061-10-12    NaN    NaN    NaN NaN    NaN    NaN    NaN NaN   3.67   3.67   \n",
      "2061-10-13    NaN    NaN    NaN NaN   6.58   6.58   6.58 NaN   8.67   8.67   \n",
      "2061-10-14    NaN    NaN    NaN NaN   4.38   4.38   4.38 NaN    NaN    NaN   \n",
      "...           ...    ...    ...  ..    ...    ...    ...  ..    ...    ...   \n",
      "2078-12-27  17.62  17.62  17.62 NaN  13.21  13.21  13.21 NaN  15.59  15.59   \n",
      "2078-12-28   5.46   5.46   5.46 NaN   5.00   5.00   5.00 NaN    NaN    NaN   \n",
      "2078-12-29  14.42  14.42  14.42 NaN    NaN    NaN    NaN NaN  19.17  19.17   \n",
      "2078-12-30  21.29  21.29  21.29 NaN  12.75  12.75  12.75 NaN  18.08  18.08   \n",
      "2078-12-31  27.29  27.29  27.29 NaN  12.08  12.08  12.08 NaN  11.63  11.63   \n",
      "\n",
      "            ...  CLO     BEL              MAL               \n",
      "            ... mean std min max mean std min max mean std  \n",
      "date        ...                                             \n",
      "2061-10-10  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2061-10-11  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2061-10-12  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2061-10-13  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2061-10-14  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "...         ...  ...  ..  ..  ..  ...  ..  ..  ..  ...  ..  \n",
      "2078-12-27  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2078-12-28  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2078-12-29  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2078-12-30  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "2078-12-31  ...  NaN NaN NaN NaN  NaN NaN NaN NaN  NaN NaN  \n",
      "\n",
      "[6292 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Calculate statistics for each day\n",
    "day_stats = data.resample('D').agg({\n",
    "    'RPT': ['min', 'max', 'mean', 'std'],\n",
    "    'VAL': ['min', 'max', 'mean', 'std'],\n",
    "    'ROS': ['min', 'max', 'mean', 'std'],\n",
    "    'KIL': ['min', 'max', 'mean', 'std'],\n",
    "    'SHA': ['min', 'max', 'mean', 'std'],\n",
    "    'BIR': ['min', 'max', 'mean', 'std'],\n",
    "    'DUB': ['min', 'max', 'mean', 'std'],\n",
    "    'CLA': ['min', 'max', 'mean', 'std'],\n",
    "    'MUL': ['min', 'max', 'mean', 'std'],\n",
    "    'CLO': ['min', 'max', 'mean', 'std'],\n",
    "    'BEL': ['min', 'max', 'mean', 'std'],\n",
    "    'MAL': ['min', 'max', 'mean', 'std']\n",
    "})\n",
    "\n",
    "#  Display the day_stats DataFrame\n",
    "print(\"Statistics for Windspeed Across All Locations Each Day:\")\n",
    "print(day_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e1f6e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly Downsampled Data for Each Location:\n",
      "              year  month        day  Unnamed: 3  Unnamed: 4        RPT  \\\n",
      "date                                                                      \n",
      "2061-12-31  2061.0   11.0  20.338462   16.566000   11.814909  15.841951   \n",
      "2062-12-31  2062.0   11.0  20.338462   15.949268   10.689818  13.582432   \n",
      "2063-12-31  2063.0   11.0  20.338462   17.883061   14.188929  14.539057   \n",
      "2064-12-31  2064.0   11.0  20.338462   16.380714   11.891379  14.196341   \n",
      "2065-12-31  2065.0   11.0  20.338462   16.221250   13.019643  14.180000   \n",
      "2066-12-31  2066.0   11.0  20.338462   15.683800   12.656200  12.500652   \n",
      "2067-12-31  2067.0   11.0  20.338462   16.297209   12.231754  12.910000   \n",
      "2068-12-31  2068.0   11.0  20.338462   16.102449   13.362083  12.840400   \n",
      "2069-12-31  2069.0   11.0  20.338462   15.225833   11.346316  14.435758   \n",
      "2070-12-31  2070.0   11.0  20.338462   15.544783   12.165472  13.799535   \n",
      "2071-12-31  2071.0   11.0  20.338462   16.390426   12.661228  15.008636   \n",
      "2072-12-31  2072.0   11.0  20.338462   16.579512   13.259167  14.032093   \n",
      "2073-12-31  2073.0   11.0  20.338462   14.787619   11.516271  13.419677   \n",
      "2074-12-31  2074.0   11.0  20.338462   18.597755   14.828621  15.031111   \n",
      "2075-12-31  2075.0   11.0  20.338462   15.897500   12.775500  14.230811   \n",
      "2076-12-31  2076.0   11.0  20.338462   15.081875   10.333276  12.045714   \n",
      "2077-12-31  2077.0   11.0  20.338462   17.443962   14.407258  14.316731   \n",
      "2078-12-31  2078.0   11.0  20.338462   17.015750   12.364211  13.752619   \n",
      "\n",
      "            Unnamed: 6  Unnamed: 7        VAL  Unnamed: 9  ...  MUL  \\\n",
      "date                                                       ...        \n",
      "2061-12-31   10.159111   12.305294   9.467321   12.319667  ...  NaN   \n",
      "2062-12-31    8.510625   11.932187   8.889464   13.017742  ...  NaN   \n",
      "2063-12-31   11.972308   12.298600  12.234000   11.875682  ...  NaN   \n",
      "2064-12-31    9.183684   10.177179   9.567660   10.262500  ...  NaN   \n",
      "2065-12-31   10.478913   11.594615   9.736792   12.319118  ...  NaN   \n",
      "2066-12-31   10.476596   12.651389   9.357551   11.902432  ...  NaN   \n",
      "2067-12-31    8.958095   12.188500   9.992642   11.931515  ...  NaN   \n",
      "2068-12-31   11.475000   11.130000   9.421509   10.913333  ...  NaN   \n",
      "2069-12-31    8.022667    9.874828   8.377547    9.420000  ...  NaN   \n",
      "2070-12-31    9.753000    9.721176   9.115536   10.148065  ...  NaN   \n",
      "2071-12-31    9.642162    9.986500  10.705965   11.788182  ...  NaN   \n",
      "2072-12-31    9.645500   10.703636   9.760444    9.811111  ...  NaN   \n",
      "2073-12-31    8.496512    9.544706   8.668846    9.673333  ...  NaN   \n",
      "2074-12-31   10.188478   14.481667   9.999074   14.420000  ...  NaN   \n",
      "2075-12-31    7.522571    9.210541   9.652745    9.624643  ...  NaN   \n",
      "2076-12-31    7.047234    7.709630   7.912308    8.555000  ...  NaN   \n",
      "2077-12-31   10.115862   10.307800  10.866078   12.336667  ...  NaN   \n",
      "2078-12-31    8.494872    9.537895   9.525510    9.665882  ...  NaN   \n",
      "\n",
      "            Unnamed: 30  Unnamed: 31  CLO  Unnamed: 33  Unnamed: 34  BEL  \\\n",
      "date                                                                       \n",
      "2061-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2062-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2063-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2064-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2065-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2066-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2067-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2068-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2069-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2070-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2071-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2072-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2073-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2074-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2075-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2076-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2077-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "\n",
      "            Unnamed: 36  Unnamed: 37  MAL  \n",
      "date                                       \n",
      "2061-12-31          NaN          NaN  NaN  \n",
      "2062-12-31          NaN          NaN  NaN  \n",
      "2063-12-31          NaN          NaN  NaN  \n",
      "2064-12-31          NaN          NaN  NaN  \n",
      "2065-12-31          NaN          NaN  NaN  \n",
      "2066-12-31          NaN          NaN  NaN  \n",
      "2067-12-31          NaN          NaN  NaN  \n",
      "2068-12-31          NaN          NaN  NaN  \n",
      "2069-12-31          NaN          NaN  NaN  \n",
      "2070-12-31          NaN          NaN  NaN  \n",
      "2071-12-31          NaN          NaN  NaN  \n",
      "2072-12-31          NaN          NaN  NaN  \n",
      "2073-12-31          NaN          NaN  NaN  \n",
      "2074-12-31          NaN          NaN  NaN  \n",
      "2075-12-31          NaN          NaN  NaN  \n",
      "2076-12-31          NaN          NaN  NaN  \n",
      "2077-12-31          NaN          NaN  NaN  \n",
      "2078-12-31          NaN          NaN  NaN  \n",
      "\n",
      "[18 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Downsample to yearly frequency for each location\n",
    "yearly_data = data.resample('Y').mean()\n",
    "\n",
    "#  Display the yearly_data DataFrame\n",
    "print(\"Yearly Downsampled Data for Each Location:\")\n",
    "print(yearly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "125a81b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Downsampled Data for Each Location:\n",
      "              year  month   day  Unnamed: 3  Unnamed: 4        RPT  \\\n",
      "date                                                                 \n",
      "2061-10-31  2061.0   10.0  20.5   17.926250   12.380000  15.567143   \n",
      "2061-11-30  2061.0   11.0  20.0   14.340909    9.925625  13.765385   \n",
      "2061-12-31  2061.0   12.0  20.5   16.716667   12.789500  18.045000   \n",
      "2062-01-31     NaN    NaN   NaN         NaN         NaN        NaN   \n",
      "2062-02-28     NaN    NaN   NaN         NaN         NaN        NaN   \n",
      "...            ...    ...   ...         ...         ...        ...   \n",
      "2078-08-31     NaN    NaN   NaN         NaN         NaN        NaN   \n",
      "2078-09-30     NaN    NaN   NaN         NaN         NaN        NaN   \n",
      "2078-10-31  2078.0   10.0  20.5   13.551429    8.213000  10.777778   \n",
      "2078-11-30  2078.0   11.0  20.0   18.382353   15.230526  14.974375   \n",
      "2078-12-31  2078.0   12.0  20.5   17.079375   13.951111  14.177647   \n",
      "\n",
      "            Unnamed: 6  Unnamed: 7        VAL  Unnamed: 9  ...  MUL  \\\n",
      "date                                                       ...        \n",
      "2061-10-31   10.727333   13.672143  10.386500   14.828182  ...  NaN   \n",
      "2061-11-30    9.786000   10.561111   7.889333    8.311818  ...  NaN   \n",
      "2061-12-31    9.964000   11.992727   9.719048   14.381250  ...  NaN   \n",
      "2062-01-31         NaN         NaN        NaN         NaN  ...  NaN   \n",
      "2062-02-28         NaN         NaN        NaN         NaN  ...  NaN   \n",
      "...                ...         ...        ...         ...  ...  ...   \n",
      "2078-08-31         NaN         NaN        NaN         NaN  ...  NaN   \n",
      "2078-09-30         NaN         NaN        NaN         NaN  ...  NaN   \n",
      "2078-10-31    5.720588    8.578750   7.581667    8.122500  ...  NaN   \n",
      "2078-11-30   10.928182   10.156429  10.471875   11.777500  ...  NaN   \n",
      "2078-12-31   10.349091    9.476250  10.848667    8.737857  ...  NaN   \n",
      "\n",
      "            Unnamed: 30  Unnamed: 31  CLO  Unnamed: 33  Unnamed: 34  BEL  \\\n",
      "date                                                                       \n",
      "2061-10-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-11-30          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2062-01-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2062-02-28          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "...                 ...          ...  ...          ...          ...  ...   \n",
      "2078-08-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-09-30          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-10-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-11-30          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-12-31          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "\n",
      "            Unnamed: 36  Unnamed: 37  MAL  \n",
      "date                                       \n",
      "2061-10-31          NaN          NaN  NaN  \n",
      "2061-11-30          NaN          NaN  NaN  \n",
      "2061-12-31          NaN          NaN  NaN  \n",
      "2062-01-31          NaN          NaN  NaN  \n",
      "2062-02-28          NaN          NaN  NaN  \n",
      "...                 ...          ...  ...  \n",
      "2078-08-31          NaN          NaN  NaN  \n",
      "2078-09-30          NaN          NaN  NaN  \n",
      "2078-10-31          NaN          NaN  NaN  \n",
      "2078-11-30          NaN          NaN  NaN  \n",
      "2078-12-31          NaN          NaN  NaN  \n",
      "\n",
      "[207 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Downsample to monthly frequency for each location\n",
    "monthly_data = data.resample('M').mean()\n",
    "\n",
    "#  Display the monthly_data DataFrame\n",
    "print(\"Monthly Downsampled Data for Each Location:\")\n",
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a122994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Downsampled Data for Each Location:\n",
      "              year  month   day  Unnamed: 3  Unnamed: 4        RPT  \\\n",
      "date                                                                 \n",
      "2061-10-16  2061.0   10.0  13.0   12.312500    9.648333  10.795000   \n",
      "2061-10-23  2061.0   10.0  20.0   20.212857   16.942000  15.281429   \n",
      "2061-10-30  2061.0   10.0  27.0   20.615000   11.695714  19.095000   \n",
      "2061-11-06  2061.0   10.0  31.0   13.620000   10.750000  13.000000   \n",
      "2061-11-13  2061.0   11.0  11.5   15.303333   10.960000  20.996667   \n",
      "...            ...    ...   ...         ...         ...        ...   \n",
      "2078-12-04  2078.0   11.0  29.0   14.900000    9.730000   7.355000   \n",
      "2078-12-11  2078.0   12.0  10.5   22.585000   20.855000  17.185000   \n",
      "2078-12-18  2078.0   12.0  15.0   17.438000   16.424000  12.343333   \n",
      "2078-12-25  2078.0   12.0  22.0   14.486667    9.453333  12.056667   \n",
      "2079-01-01  2078.0   12.0  28.5   16.241667   14.114000  16.070000   \n",
      "\n",
      "            Unnamed: 6  Unnamed: 7        VAL  Unnamed: 9  ...  MUL  \\\n",
      "date                                                       ...        \n",
      "2061-10-16    7.710000      8.6400   8.515000   10.657500  ...  NaN   \n",
      "2061-10-23   14.193333     18.0100  11.710000   19.450000  ...  NaN   \n",
      "2061-10-30    8.982000     13.4220  10.528333   14.226667  ...  NaN   \n",
      "2061-11-06         NaN      8.3300  11.500000         NaN  ...  NaN   \n",
      "2061-11-13   12.670000      8.7900   8.363333    9.275000  ...  NaN   \n",
      "...                ...         ...        ...         ...  ...  ...   \n",
      "2078-12-04   11.000000      3.3300   5.940000    9.590000  ...  NaN   \n",
      "2078-12-11   13.125000     16.6900  13.185000   14.020000  ...  NaN   \n",
      "2078-12-18   12.373333      7.7375  11.068333    8.070000  ...  NaN   \n",
      "2078-12-25    7.402000      9.8820   8.970000    6.322000  ...  NaN   \n",
      "2079-01-01   13.460000      7.5760  10.760000    9.617500  ...  NaN   \n",
      "\n",
      "            Unnamed: 30  Unnamed: 31  CLO  Unnamed: 33  Unnamed: 34  BEL  \\\n",
      "date                                                                       \n",
      "2061-10-16          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-10-23          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-10-30          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-11-06          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2061-11-13          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "...                 ...          ...  ...          ...          ...  ...   \n",
      "2078-12-04          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-12-11          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-12-18          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2078-12-25          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "2079-01-01          NaN          NaN  NaN          NaN          NaN  NaN   \n",
      "\n",
      "            Unnamed: 36  Unnamed: 37  MAL  \n",
      "date                                       \n",
      "2061-10-16          NaN          NaN  NaN  \n",
      "2061-10-23          NaN          NaN  NaN  \n",
      "2061-10-30          NaN          NaN  NaN  \n",
      "2061-11-06          NaN          NaN  NaN  \n",
      "2061-11-13          NaN          NaN  NaN  \n",
      "...                 ...          ...  ...  \n",
      "2078-12-04          NaN          NaN  NaN  \n",
      "2078-12-11          NaN          NaN  NaN  \n",
      "2078-12-18          NaN          NaN  NaN  \n",
      "2078-12-25          NaN          NaN  NaN  \n",
      "2079-01-01          NaN          NaN  NaN  \n",
      "\n",
      "[899 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Downsample to weekly frequency for each location\n",
    "weekly_data = data.resample('W').mean()\n",
    "\n",
    "# Display the weekly_data DataFrame\n",
    "print(\"Weekly Downsampled Data for Each Location:\")\n",
    "print(weekly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff6788b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Statistics for Windspeed Across All Locations:\n",
      "              RPT                                 VAL                    \\\n",
      "              min    max       mean        std    min    max       mean   \n",
      "date                                                                      \n",
      "2061-10-16  10.13  11.46  10.795000   0.940452   4.21  13.54   8.515000   \n",
      "2061-10-23   3.75  22.63  15.281429   7.024254   6.83  16.42  11.710000   \n",
      "2061-10-30  13.00  23.09  19.095000   4.839921   4.79  15.46  10.528333   \n",
      "2061-11-06  13.00  13.00  13.000000        NaN  11.50  11.50  11.500000   \n",
      "2061-11-13   9.87  32.71  20.996667  11.431296   6.92   9.59   8.363333   \n",
      "...           ...    ...        ...        ...    ...    ...        ...   \n",
      "2078-12-04   4.54  10.17   7.355000   3.981011   3.50   8.38   5.940000   \n",
      "2078-12-11  16.54  17.83  17.185000   0.912168  13.00  13.37  13.185000   \n",
      "2078-12-18   8.92  18.05  12.343333   3.492676   5.21  18.12  11.068333   \n",
      "2078-12-25   3.83  22.21  12.056667   9.340243   4.79  14.29   8.970000   \n",
      "2079-01-01   5.46  27.29  16.070000   7.793161   5.00  13.21  10.760000   \n",
      "\n",
      "                        ROS         ...  CLO     BEL              MAL      \\\n",
      "                 std    min    max  ... mean std min max mean std min max   \n",
      "date                                ...                                     \n",
      "2061-10-16  4.166009   3.67  12.71  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2061-10-23  3.264772  13.21  18.00  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2061-10-30  4.352450  15.37  15.37  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2061-11-06       NaN  15.25  15.25  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2061-11-13  1.348122   5.17  10.04  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "...              ...    ...    ...  ...  ...  ..  ..  ..  ...  ..  ..  ..   \n",
      "2078-12-04  3.450681   8.83   8.83  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2078-12-11  0.261630  15.54  16.21  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2078-12-18  5.068954   9.08  13.75  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2078-12-25  4.851515   3.50  17.16  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "2079-01-01  3.867928   4.29  19.17  ...  NaN NaN NaN NaN  NaN NaN NaN NaN   \n",
      "\n",
      "                     \n",
      "           mean std  \n",
      "date                 \n",
      "2061-10-16  NaN NaN  \n",
      "2061-10-23  NaN NaN  \n",
      "2061-10-30  NaN NaN  \n",
      "2061-11-06  NaN NaN  \n",
      "2061-11-13  NaN NaN  \n",
      "...         ...  ..  \n",
      "2078-12-04  NaN NaN  \n",
      "2078-12-11  NaN NaN  \n",
      "2078-12-18  NaN NaN  \n",
      "2078-12-25  NaN NaN  \n",
      "2079-01-01  NaN NaN  \n",
      "\n",
      "[899 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Downsample to weekly frequency and calculate statistics\n",
    "weekly_stats = data.resample('W').agg({\n",
    "    'RPT': ['min', 'max', 'mean', 'std'],\n",
    "    'VAL': ['min', 'max', 'mean', 'std'],\n",
    "    'ROS': ['min', 'max', 'mean', 'std'],\n",
    "    'KIL': ['min', 'max', 'mean', 'std'],\n",
    "    'SHA': ['min', 'max', 'mean', 'std'],\n",
    "    'BIR': ['min', 'max', 'mean', 'std'],\n",
    "    'DUB': ['min', 'max', 'mean', 'std'],\n",
    "    'CLA': ['min', 'max', 'mean', 'std'],\n",
    "    'MUL': ['min', 'max', 'mean', 'std'],\n",
    "    'CLO': ['min', 'max', 'mean', 'std'],\n",
    "    'BEL': ['min', 'max', 'mean', 'std'],\n",
    "    'MAL': ['min', 'max', 'mean', 'std']\n",
    "})\n",
    "\n",
    "#  Display the weekly_stats DataFrame\n",
    "print(\"Weekly Statistics for Windspeed Across All Locations:\")\n",
    "print(weekly_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7b2a6",
   "metadata": {},
   "source": [
    "<h2>Question 5</h2>\n",
    "Step 1. Import the necessary libraries <br>\n",
    "Step 2. Import the dataset from this address. <br>\n",
    "Step 3. Assign it to a variable called chipo. <br>\n",
    "Step 4. See the first 10 entries<br>\n",
    "Step 5. What is the number of observations in the dataset? <br>\n",
    "Step 6. What is the number of columns in the dataset?<br>\n",
    "Step 7. Print the name of all the columns. <br>\n",
    "Step 8. How is the dataset indexed?<br>\n",
    "Step 9. Which was the most-ordered item?<br>\n",
    "Step 10. For the most-ordered item, how many items were ordered?<br>\n",
    "Step 11. What was the most ordered item in the choice_description column? <br>\n",
    "Step 12. How many items were orderd in total?<br>\n",
    "Step 13.<ul>\n",
    "<li>Turn the item price into a float</li>\n",
    "<li>Check the item price type</li>\n",
    "<li>Create a lambda function and change the type of item price</li>\n",
    "<li>Check the item price type</li></ul>\n",
    "Step 14. How much was the revenue for the period in the dataset? <br>\n",
    "Step 15. How many orders were made in the period? <br>\n",
    "Step 16. What is the average revenue amount per order? <br>\n",
    "Step 17. How many different items are sold? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce4b848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Import the dataset\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv\"\n",
    "\n",
    "#  Assign it to a variable called chipo\n",
    "chipo = pd.read_csv(url, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44cee365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 entries\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|    |   order_id |   quantity | item_name                             | choice_description                                                                                                 | item_price   |\n",
      "+====+============+============+=======================================+====================================================================================================================+==============+\n",
      "|  0 |          1 |          1 | Chips and Fresh Tomato Salsa          | nan                                                                                                                | $2.39        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  1 |          1 |          1 | Izze                                  | [Clementine]                                                                                                       | $3.39        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  2 |          1 |          1 | Nantucket Nectar                      | [Apple]                                                                                                            | $3.39        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  3 |          1 |          1 | Chips and Tomatillo-Green Chili Salsa | nan                                                                                                                | $2.39        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  4 |          2 |          2 | Chicken Bowl                          | [Tomatillo-Red Chili Salsa (Hot), [Black Beans, Rice, Cheese, Sour Cream]]                                         | $16.98       |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  5 |          3 |          1 | Chicken Bowl                          | [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sour Cream, Guacamole, Lettuce]]                                        | $10.98       |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  6 |          3 |          1 | Side of Chips                         | nan                                                                                                                | $1.69        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  7 |          4 |          1 | Steak Burrito                         | [Tomatillo Red Chili Salsa, [Fajita Vegetables, Black Beans, Pinto Beans, Cheese, Sour Cream, Guacamole, Lettuce]] | $11.75       |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  8 |          4 |          1 | Steak Soft Tacos                      | [Tomatillo Green Chili Salsa, [Pinto Beans, Cheese, Sour Cream, Lettuce]]                                          | $9.25        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "|  9 |          5 |          1 | Steak Burrito                         | [Fresh Tomato Salsa, [Rice, Black Beans, Pinto Beans, Cheese, Sour Cream, Lettuce]]                                | $9.25        |\n",
      "+----+------------+------------+---------------------------------------+--------------------------------------------------------------------------------------------------------------------+--------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the first 10 entries\n",
    "print(\"First 10 entries\")\n",
    "print(tabulate(chipo.head(10), headers='keys', tablefmt='grid'))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "784acbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the dataset: 4622\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  What is the number of observations in the dataset?\n",
    "num_observations = chipo.shape[0]\n",
    "print(\"Number of observations in the dataset:\", num_observations)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4da50f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataset: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  What is the number of columns in the dataset?\n",
    "num_columns = chipo.shape[1]\n",
    "print(\"Number of columns in the dataset:\", num_columns)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0283bd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tabulate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  Print the name of all the columns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn names:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(pd\u001b[38;5;241m.\u001b[39mDataFrame(chipo\u001b[38;5;241m.\u001b[39mcolumns, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn Name\u001b[39m\u001b[38;5;124m'\u001b[39m]), headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m, tablefmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tabulate' is not defined"
     ]
    }
   ],
   "source": [
    "#  Print the name of all the columns\n",
    "print(\"Column names:\")\n",
    "print(tabulate(pd.DataFrame(chipo.columns, columns=['Column Name']), headers='keys', tablefmt='grid'))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10261dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indexing:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chipo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  How is the dataset indexed?\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset indexing:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m index_sample \u001b[38;5;241m=\u001b[39m chipo\u001b[38;5;241m.\u001b[39mindex[:\u001b[38;5;241m10\u001b[39m]  \u001b[38;5;66;03m# Get the first 10 indices\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(pd\u001b[38;5;241m.\u001b[39mDataFrame(index_sample, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m]), headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m, tablefmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Indicate that the output is truncated\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chipo' is not defined"
     ]
    }
   ],
   "source": [
    "#  How is the dataset indexed?\n",
    "print(\"Dataset indexing:\")\n",
    "index_sample = chipo.index[:10]  # Get the first 10 indices\n",
    "print(tabulate(pd.DataFrame(index_sample, columns=['Index']), headers='keys', tablefmt='grid'))\n",
    "print(\"...\")  # Indicate that the output is truncated\n",
    "print(\"...\")  # Indicate that the output is truncated\n",
    "print(\"...\")  # Indicate that the output is truncated\n",
    "print(\"...\")  # Indicate that the output is truncated\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc88fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most-ordered item: Chicken Bowl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Which was the most-ordered item?\n",
    "most_ordered_item = chipo['item_name'].value_counts().idxmax()\n",
    "print(\"Most-ordered item:\", most_ordered_item)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89c74034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items ordered for the most-ordered item: 761\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  For the most-ordered item, how many items were ordered?\n",
    "most_ordered_item_count = chipo[chipo['item_name'] == most_ordered_item]['quantity'].sum()\n",
    "print(\"Number of items ordered for the most-ordered item:\", most_ordered_item_count)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04a49635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most ordered item in the choice_description column: [Diet Coke]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  What was the most ordered item in the choice_description column?\n",
    "most_ordered_choice = chipo['choice_description'].value_counts().idxmax()\n",
    "print(\"Most ordered item in the choice_description column:\", most_ordered_choice)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8318776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items ordered: 4972\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  How many items were ordered in total?\n",
    "total_items_ordered = chipo['quantity'].sum()\n",
    "print(\"Total number of items ordered:\", total_items_ordered)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06bba72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item price type after conversion:\n",
      "float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert item price to float\n",
    "chipo['item_price'] = chipo['item_price'].apply(lambda x: float(x[1:]))\n",
    "\n",
    "# Checking item price type after conversion\n",
    "print(\"Item price type after conversion:\")\n",
    "print(chipo['item_price'].dtype)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0eeb08d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue for the period: 39237.02\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  How much was the revenue for the period in the dataset?\n",
    "revenue = (chipo['quantity'] * chipo['item_price']).sum()\n",
    "print(\"Total revenue for the period:\", revenue)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79f7792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders made in the period: 1834\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  How many orders were made in the period?\n",
    "num_orders = chipo['order_id'].nunique()\n",
    "print(\"Number of orders made in the period:\", num_orders)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c63b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average revenue amount per order: 21.39423118865867\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  What is the average revenue amount per order?\n",
    "average_revenue_per_order = revenue / num_orders\n",
    "print(\"Average revenue amount per order:\", average_revenue_per_order)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7196f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items sold: 50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  How many different items are sold?\n",
    "num_different_items = chipo['item_name'].nunique()\n",
    "print(\"Number of different items sold:\", num_different_items)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faaf36c",
   "metadata": {},
   "source": [
    "<h2>Question 6</h2>\n",
    "Create a line plot showing the number of marriages and divorces per capita in the\n",
    "U.S. between 1867 and 2014. Label both lines and show the legend. \n",
    "Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64742443",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'us-marriages-divorces-1867-2014.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loads the dataset containing U.S. marriage and divorce rates from 1867 to 2014\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-marriages-divorces-1867-2014.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Creates a line plot to visualize the historical trends in U.S. marriage and divorce rates\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m8\u001b[39m)) \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'us-marriages-divorces-1867-2014.csv'"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the dataset containing U.S. marriage and divorce rates from 1867 to 2014\n",
    "file_path = \"us-marriages-divorces-1867-2014.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Creates a line plot to visualize the historical trends in U.S. marriage and divorce rates\n",
    "plt.figure(figsize=(9.5, 8)) \n",
    "\n",
    "# Plots the data for marriages and divorces per 1000 people\n",
    "plt.plot(data['Year'], data['Marriages_per_1000'], label='Marriages', color='blue')\n",
    "plt.plot(data['Year'], data['Divorces_per_1000'], label='Divorces', color='red')\n",
    "\n",
    "# Sets labels and title for the plot\n",
    "plt.xlabel('Year', fontweight='bold', fontsize=13)  # Label for x-axis\n",
    "plt.ylabel('Rate per 1000 People', fontweight='bold', fontsize=13)  # Label for y-axis\n",
    "plt.title('Trends in Marriages and Divorces per Capita in the U.S. (1867-2014)', fontweight='bold', fontsize=15)\n",
    "\n",
    "# Adds legend to distinguish between marriages and divorces\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "# Ensures a clean layout and display the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bf2ed",
   "metadata": {},
   "source": [
    "<h2>Question 7</h2>\n",
    "Create a vertical bar chart comparing the number of marriages and divorces per \n",
    "capita in the U.S. between 1900, 1950, and 2000.<br>\n",
    "Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce94081",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'us-marriages-divorces-1867-2014.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loads the dataset containing U.S. marriage and divorce rates from 1867 to 2014\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-marriages-divorces-1867-2014.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Filters data for specific years of interest: 1900, 1950, and 2000\u001b[39;00m\n\u001b[0;32m     10\u001b[0m years_of_interest \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1900\u001b[39m, \u001b[38;5;241m1950\u001b[39m, \u001b[38;5;241m2000\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'us-marriages-divorces-1867-2014.csv'"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the dataset containing U.S. marriage and divorce rates from 1867 to 2014\n",
    "file_path = \"us-marriages-divorces-1867-2014.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filters data for specific years of interest: 1900, 1950, and 2000\n",
    "years_of_interest = [1900, 1950, 2000]\n",
    "filtered_data = data[data['Year'].isin(years_of_interest)]\n",
    "\n",
    "# Creates a vertical bar chart with custom styles\n",
    "plt.figure(figsize=(9.5, 8)) \n",
    "\n",
    "# Sets the width of the bars for grouping\n",
    "bar_width = 12.0\n",
    "\n",
    "# Plots the data for marriages and divorces per 1000 people\n",
    "marriages_bars = plt.bar(filtered_data['Year'] - bar_width/2, filtered_data['Marriages_per_1000'], width=bar_width, label='Marriages per 1000', alpha=0.7, color='darkorange')\n",
    "divorces_bars = plt.bar(filtered_data['Year'] + bar_width/2, filtered_data['Divorces_per_1000'], width=bar_width, label='Divorces per 1000', alpha=0.7, color='teal')\n",
    "\n",
    "# Sets labels and title with appropriate formatting\n",
    "plt.xlabel('Year', fontweight='bold', fontsize=12)  # X-axis label\n",
    "plt.ylabel('Rate per 1000 People', fontweight='bold', fontsize=12)  # Y-axis label\n",
    "plt.title('Comparison of Marriages and Divorces per Capita in the U.S. (1900, 1950, 2000)', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Adds legend to distinguish between marriages and divorces\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "# Adds numerical values on top of the bars to indicate rates\n",
    "for bar in marriages_bars + divorces_bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Displays the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90070e5",
   "metadata": {},
   "source": [
    "<h2>Question 8</h2>\n",
    "Create a horizontal bar chart that compares the deadliest actors in Hollywood. Sort \n",
    "the actors by their kill count and label each bar with the corresponding actor's name. <br>\n",
    "Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3378e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'actor_kill_counts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loads the dataset containing actor kill counts\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactor_kill_counts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Sorts the data by kill count in ascending order\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'actor_kill_counts.csv'"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the dataset containing actor kill counts\n",
    "file_path = \"actor_kill_counts.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sorts the data by kill count in ascending order\n",
    "sorted_data = data.sort_values(by='Count', ascending=True)\n",
    "\n",
    "# Creates a horizontal bar chart to visualize deadliest actors\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "\n",
    "# Increases the gap between bars for better visibility\n",
    "bar_gap = 0.4\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.barh(sorted_data['Actor'], sorted_data['Count'], color='steelblue', height=bar_gap)\n",
    "\n",
    "# Set labels and title for the chart\n",
    "plt.xlabel('Kill Count', fontweight='bold', fontsize=12)  # X-axis label\n",
    "plt.ylabel('Actor', fontweight='bold', fontsize=12)  # Y-axis label\n",
    "plt.title('Deadliest Actors in Hollywood', fontweight='bold', fontsize=14) \n",
    "\n",
    "# Adds kill count values as labels to the bars\n",
    "for index, value in enumerate(sorted_data['Count']):\n",
    "    plt.text(value, index, str(value), ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Customizes the appearance of the chart\n",
    "plt.grid(axis='x', linestyle='', alpha=0.7)  \n",
    "plt.tight_layout() \n",
    "\n",
    "# Displays the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965b51e",
   "metadata": {},
   "source": [
    "<h2>Question 9</h2>\n",
    "Create a pie chart showing the fraction of all Roman Emperors that were \n",
    "assassinated.<br>\n",
    "Make sure that the pie chart is an even circle, labels the categories, and shows the \n",
    "percentage breakdown of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dc805e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'roman-emperor-reigns.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loads the dataset containing information about Roman emperor reigns and causes of death\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroman-emperor-reigns.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Calculates the number of emperors who died from assassination\u001b[39;00m\n\u001b[0;32m     10\u001b[0m assassinated_emperors \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCause_of_Death\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssassinated\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'roman-emperor-reigns.csv'"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the dataset containing information about Roman emperor reigns and causes of death\n",
    "file_path = \"roman-emperor-reigns.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculates the number of emperors who died from assassination\n",
    "assassinated_emperors = data[data['Cause_of_Death'] == 'Assassinated']\n",
    "total_emperors = len(data)\n",
    "assassinated_count = len(assassinated_emperors)\n",
    "\n",
    "# Calculates the percentage of emperors who died from assassination\n",
    "percentage_assassinated = (assassinated_count / total_emperors) * 100\n",
    "\n",
    "# Creates a pie chart to visualize the causes of death\n",
    "plt.figure(figsize=(8, 8))  # Set the figure size\n",
    "\n",
    "# Colours to display in the chart\n",
    "color_palette = ['lightblue', 'teal']\n",
    "\n",
    "# Plots the pie chart with custom labels, colors, and formatting\n",
    "plt.pie([assassinated_count, total_emperors - assassinated_count], \n",
    "        labels=['Assassinated', 'Other Causes'], colors=color_palette,\n",
    "        autopct='%1.1f%%', startangle=140, textprops={'weight': 'bold'},\n",
    "        wedgeprops={'linewidth': 1, 'edgecolor': 'black'})  \n",
    "\n",
    "# Sets the aspect ratio to make the pie chart a circle\n",
    "plt.axis('equal')\n",
    "\n",
    "# Sets the title for the pie chart\n",
    "plt.title('Fraction of Roman Emperors by Cause of Death', fontweight='bold')\n",
    "\n",
    "# Adds a legend to the pie chart\n",
    "plt.legend()\n",
    "\n",
    "# Displays the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345d790",
   "metadata": {},
   "source": [
    "<h2>Question 10</h2>\n",
    "Create a scatter plot showing the relationship between the total revenue earned by \n",
    "arcades and the number of Computer Science PhDs awarded in the U.S. between \n",
    "2000 and 2009.<br>\n",
    "Don't forget to label your axes! <br>\n",
    "Color each dot according to its year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64275aaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arcade-revenue-vs-cs-doctorates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loads the dataset containing information about arcade revenue and CS doctorates\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marcade-revenue-vs-cs-doctorates.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Creates a scatter plot to visualize the relationship between arcade revenue and CS doctorates\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m8\u001b[39m))  \u001b[38;5;66;03m# Set the figure size\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arcade-revenue-vs-cs-doctorates.csv'"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the dataset containing information about arcade revenue and CS doctorates\n",
    "file_path = \"arcade-revenue-vs-cs-doctorates.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Creates a scatter plot to visualize the relationship between arcade revenue and CS doctorates\n",
    "plt.figure(figsize=(9.5, 8))  # Set the figure size\n",
    "\n",
    "# Defines a continuous color map for smooth gradient\n",
    "color_map = \"viridis\"\n",
    "\n",
    "# Plots the data points with color-coded years and smooth color gradient\n",
    "scatter = plt.scatter(data['Total Arcade Revenue (billions)'], data['Computer Science Doctorates Awarded (US)'],\n",
    "                      c=data['Year'], cmap=color_map, s=80, edgecolors='black', alpha=0.8)  \n",
    "\n",
    "# Sets labels and title with bold formatting\n",
    "plt.xlabel('Total Arcade Revenue (billions)', fontweight='bold', fontsize=12)  # X-axis label\n",
    "plt.ylabel('Computer Science Doctorates Awarded (US)', fontweight='bold', fontsize=12)  # Y-axis label\n",
    "plt.title('Relationship between Arcade Revenue and CS Doctorates (2000-2009)', fontweight='bold', fontsize=14)  \n",
    "\n",
    "# Adds year as text to each data point with proper alignment and formatting\n",
    "for i, year in enumerate(data['Year']):\n",
    "    plt.text(data['Total Arcade Revenue (billions)'][i], data['Computer Science Doctorates Awarded (US)'][i], str(year),\n",
    "             fontsize=10, ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Adds a colorbar to indicate the years\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Year')\n",
    "\n",
    "# Customizes the appearance of the chart\n",
    "plt.grid(alpha=0.3)  \n",
    "plt.tight_layout()  \n",
    "\n",
    "# Displays the scatter plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89baadf9",
   "metadata": {},
   "source": [
    "<h3>Thank You!</h3>\n",
    "<h2>End of ProblemSet 3 Solutions</h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
